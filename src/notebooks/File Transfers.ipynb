{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Basic working file for move files to and from linux and between buckets in google cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Skjema Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aar = '2023'\n",
    "\n",
    "\n",
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-skatt-naering-data-synk-opp/test/dynadata_5823.parquet\"\n",
    "    )\n",
    "    # if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Use the ParquetDataset to read multiple files\n",
    "dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "table = dataset.read()\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "# skjema = table.to_pandas()\n",
    "\n",
    "# Create a PyArrow array filled with the value '2022' for each row\n",
    "# Create the 'aar' column as a categorical (dictionary-encoded) string\n",
    "num_rows = table.num_rows\n",
    "year_array = pa.array([aar] * num_rows, type=pa.string())\n",
    "year_array = pa.DictionaryArray.from_arrays(pa.array(range(num_rows), type=pa.int32()), year_array)\n",
    "\n",
    "# Add the new column to your existing table\n",
    "table_with_aar = table.append_column('aar', year_array)\n",
    "\n",
    "columns = {\n",
    "    \"ENHETS_ID\": \"id\",\n",
    "    \"RAD_NR\": \"radnr\",\n",
    "    \"FELT_ID\": \"feltnavn\",\n",
    "    \"FELT_VERDI\": \"feltverdi\",\n",
    "    \"SKJEMA\": \"skjema\",\n",
    "    \"LOPENR\": \"lopenr\",\n",
    "    \"AKTIV\": \"aktiv\",\n",
    "    \"DELREG_NR\": \"delreg\",\n",
    "}\n",
    "\n",
    "# Get the current schema of the table with the 'aar' column\n",
    "schema = table_with_aar.schema\n",
    "\n",
    "# Create a list to hold the new fields with renamed column names\n",
    "new_fields = []\n",
    "\n",
    "# Loop through the current schema and rename the columns based on the mapping\n",
    "for field in schema:\n",
    "    new_name = columns.get(field.name, field.name)  # Rename if in mapping, else keep the original name\n",
    "    new_fields.append(pa.field(new_name, field.type))\n",
    "\n",
    "# Create a new schema with the renamed fields\n",
    "new_schema = pa.schema(new_fields)\n",
    "\n",
    "# Apply the new schema to the table with 'aar' column by reconstructing it\n",
    "table_renamed = pa.Table.from_arrays(table_with_aar.columns, schema=new_schema)\n",
    "\n",
    "# Verify the result\n",
    "print(table_renamed.schema)\n",
    "\n",
    "pq.write_table(\n",
    "    table_renamed,\n",
    "    f\"gs://ssb-prod-noeku-data-produkt/eimerdb/nokubasen/skjemadata/aar={aar}/skjema=RA-1403/skjemadata_data_0.parquet\",\n",
    "    filesystem=fs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Statistiskfilene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "## Bedrift NR\n",
    "\n",
    "\n",
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-skatt-naering-data-synk-opp/test/statistikkfil_bedrifter_nr_{year}.parquet\"\n",
    "    )\n",
    "    # if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Use the ParquetDataset to read multiple files\n",
    "dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "table1 = dataset.read()\n",
    "\n",
    "\n",
    "pq.write_table(\n",
    "    table1,\n",
    "    f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistikkfil_bedrifter_nr.parquet\",\n",
    "    filesystem=fs\n",
    ")\n",
    "\n",
    "# pq.write_table(\n",
    "#     table1,\n",
    "#     f\"gs://ssb-prod-noeku-data-delt/statistikkfiler/g{year}/statistikkfil_bedrifter_nr.parquet\",\n",
    "#     filesystem=fs\n",
    "# )\n",
    "\n",
    "del table1, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Bedrift Pub\n",
    "\n",
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-skatt-naering-data-synk-opp/test/statistikkfil_bedrifter_pub_{year}.parquet\"\n",
    "    )\n",
    "    # if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Use the ParquetDataset to read multiple files\n",
    "dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "table2 = dataset.read()\n",
    "\n",
    "table2.columns = table2.columns.str.lower()\n",
    "\n",
    "\n",
    "pq.write_table(\n",
    "    table2,\n",
    "    f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistikkfil_bedrifter_pub.parquet\",\n",
    "    filesystem=fs\n",
    ")\n",
    "\n",
    "# pq.write_table(\n",
    "#     table2,\n",
    "#     f\"gs://ssb-prod-noeku-data-delt/statistikkfiler/g{year}/statistikkfil_bedrifter_pub.parquet\",\n",
    "#     filesystem=fs\n",
    "# )\n",
    "\n",
    "del table2, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Foretak NR\n",
    "\n",
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-skatt-naering-data-synk-opp/test/statistikkfil_foretak_nr_{year}.parquet\"\n",
    "    )\n",
    "    # if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Use the ParquetDataset to read multiple files\n",
    "dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "table3 = dataset.read()\n",
    "\n",
    "\n",
    "pq.write_table(\n",
    "    table3,\n",
    "    f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistikkfil_foretak_nr.parquet\",\n",
    "    filesystem=fs\n",
    ")\n",
    "\n",
    "# pq.write_table(\n",
    "#     table3,\n",
    "#     f\"gs://ssb-prod-noeku-data-delt/statistikkfiler/g{year}/statistikkfil_foretak_nr.parquet\",\n",
    "#     filesystem=fs\n",
    "# )\n",
    "\n",
    "del table3, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Foretak PUB\n",
    "\n",
    "\n",
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-skatt-naering-data-synk-opp/test/statistikkfil_foretak_pub_{year}.parquet\"\n",
    "    )\n",
    "    # if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Use the ParquetDataset to read multiple files\n",
    "dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "table4 = dataset.read()\n",
    "foretak_pub = table4.to_pandas()\n",
    "\n",
    "foretak_pub.columns = foretak_pub.columns.str.lower()\n",
    "\n",
    "\n",
    "# pq.write_table(\n",
    "#     table4,\n",
    "#     f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistikkfil_foretak_pub.parquet\",\n",
    "#     filesystem=fs\n",
    "# )\n",
    "\n",
    "\n",
    "foretak_pub.to_parquet(\n",
    "    f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistikkfil_foretak_pub.parquet\",\n",
    "    storage_options={\"token\": AuthClient.fetch_google_credentials()},\n",
    ")\n",
    "\n",
    "\n",
    "# pq.write_table(\n",
    "#     table4,\n",
    "#     f\"gs://ssb-prod-noeku-data-delt/statistikkfiler/g{year}/statistikkfil_foretak_pub.parquet\",\n",
    "#     filesystem=fs\n",
    "# )\n",
    "\n",
    "# del table4, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del table4, dataset\n",
    "\n",
    "# print option all cols\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "foretak_pub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(foretak_pub.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "2023 skjema data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-skatt-naering-data-synk-opp/test/dynadata_6023.parquet\"\n",
    "    )\n",
    "    # if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Use the ParquetDataset to read multiple files\n",
    "dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "table = dataset.read()\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "# skjema = table.to_pandas()\n",
    "\n",
    "# Create a PyArrow array filled with the value '2022' for each row\n",
    "# Create the 'aar' column as a categorical (dictionary-encoded) string\n",
    "num_rows = table.num_rows\n",
    "year_array = pa.array(['2023'] * num_rows, type=pa.string())\n",
    "year_array = pa.DictionaryArray.from_arrays(pa.array(range(num_rows), type=pa.int32()), year_array)\n",
    "\n",
    "# Add the new column to your existing table\n",
    "table_with_aar = table.append_column('aar', year_array)\n",
    "\n",
    "columns = {\n",
    "    \"ENHETS_ID\": \"id\",\n",
    "    \n",
    "    \"RAD_NR\": \"radnr\",\n",
    "    \"FELT_ID\": \"feltnavn\",\n",
    "    \"FELT_VERDI\": \"feltverdi\",\n",
    "    \"SKJEMA\": \"skjema\",\n",
    "    \"LOPENR\": \"lopenr\",\n",
    "    \"AKTIV\": \"aktiv\",\n",
    "    \"DELREG_NR\": \"delreg\",\n",
    "    \"ENHETS_TYPE\": \"enhets_type\"\n",
    "}\n",
    "\n",
    "# Get the current schema of the table with the 'aar' column\n",
    "schema = table_with_aar.schema\n",
    "\n",
    "# Create a list to hold the new fields with renamed column names\n",
    "new_fields = []\n",
    "\n",
    "# Loop through the current schema and rename the columns based on the mapping\n",
    "for field in schema:\n",
    "    new_name = columns.get(field.name, field.name)  # Rename if in mapping, else keep the original name\n",
    "    new_fields.append(pa.field(new_name, field.type))\n",
    "\n",
    "# Create a new schema with the renamed fields\n",
    "new_schema = pa.schema(new_fields)\n",
    "\n",
    "# Apply the new schema to the table with 'aar' column by reconstructing it\n",
    "table_renamed = pa.Table.from_arrays(table_with_aar.columns, schema=new_schema)\n",
    "\n",
    "# Verify the result\n",
    "print(table_renamed.schema)\n",
    "\n",
    "pq.write_table(\n",
    "    table_renamed,\n",
    "    f\"gs://ssb-prod-noeku-data-produkt/eimerdb/nokubasen/skjemadata/aar=2023/skjema=RA-0174-1/skjemadata_data_0.parquet\",\n",
    "    filesystem=fs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-skatt-naering-data-synk-opp/test/dynadata_5923.parquet\"\n",
    "    )\n",
    "    # if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Use the ParquetDataset to read multiple files\n",
    "dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "table = dataset.read()\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "# skjema = table.to_pandas()\n",
    "\n",
    "# Create a PyArrow array filled with the value '2022' for each row\n",
    "# Create the 'aar' column as a categorical (dictionary-encoded) string\n",
    "num_rows = table.num_rows\n",
    "year_array = pa.array(['2023'] * num_rows, type=pa.string())\n",
    "year_array = pa.DictionaryArray.from_arrays(pa.array(range(num_rows), type=pa.int32()), year_array)\n",
    "\n",
    "# Add the new column to your existing table\n",
    "table_with_aar = table.append_column('aar', year_array)\n",
    "\n",
    "columns = {\n",
    "    \"ENHETS_ID\": \"id\",\n",
    "    \n",
    "    \"RAD_NR\": \"radnr\",\n",
    "    \"FELT_ID\": \"feltnavn\",\n",
    "    \"FELT_VERDI\": \"feltverdi\",\n",
    "    \"SKJEMA\": \"skjema\",\n",
    "    \"LOPENR\": \"lopenr\",\n",
    "    \"AKTIV\": \"aktiv\",\n",
    "    \"DELREG_NR\": \"delreg\",\n",
    "    \"ENHETS_TYPE\": \"enhets_type\"\n",
    "}\n",
    "\n",
    "# Get the current schema of the table with the 'aar' column\n",
    "schema = table_with_aar.schema\n",
    "\n",
    "# Create a list to hold the new fields with renamed column names\n",
    "new_fields = []\n",
    "\n",
    "# Loop through the current schema and rename the columns based on the mapping\n",
    "for field in schema:\n",
    "    new_name = columns.get(field.name, field.name)  # Rename if in mapping, else keep the original name\n",
    "    new_fields.append(pa.field(new_name, field.type))\n",
    "\n",
    "# Create a new schema with the renamed fields\n",
    "new_schema = pa.schema(new_fields)\n",
    "\n",
    "# Apply the new schema to the table with 'aar' column by reconstructing it\n",
    "table_renamed = pa.Table.from_arrays(table_with_aar.columns, schema=new_schema)\n",
    "\n",
    "# Verify the result\n",
    "print(table_renamed.schema)\n",
    "\n",
    "pq.write_table(\n",
    "    table_renamed,\n",
    "    f\"gs://ssb-prod-noeku-data-produkt/eimerdb/nokubasen/skjemadata/aar=2023/skjema=RA-0255-1/skjemadata_data_0.parquet\",\n",
    "    filesystem=fs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_year = '2023'\n",
    "skjema_list = 'RA-0174-1'\n",
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-noeku-data-produkt/eimerdb/nokubasen/skjemadata/aar={current_year}/skjema={skjema_list}/*\"\n",
    "    )\n",
    "    if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Assuming there's only one file in fil_path\n",
    "if fil_path:\n",
    "    skjema = pd.read_parquet(fil_path[0], filesystem=fs)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"No Parquet files found for year {current_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "felt_id_values = [\n",
    "    \"V_ORGNR\",\n",
    "    \"F_ADRESSE\",\n",
    "    \"FJOR_NACE_B_T1\",\n",
    "    \"TMP_SN2007_5\",\n",
    "    \"B_KOMMUNENR\",\n",
    "    \"REGTYPE\",\n",
    "    \"B_SYSSELSETTING_SYSS\",\n",
    "    \"TMP_NY_BDR_SYSS\",\n",
    "    \"GJELDENDE_BDR_SYSS\",\n",
    "    \"FJOR_SYSSEL_T1\",\n",
    "    \"LONN_PST_AORDN\",\n",
    "    \"GJELDENDE_LONN_KR\",\n",
    "    \"LONN\",\n",
    "    \"FJOR_LONN_KR_T1\",\n",
    "    \"TMP_SNITTLONN\",\n",
    "    \"FJOR_SNITTLONN_T1\",\n",
    "    \"GJELDENDE_OMSETN_KR\",\n",
    "    \"OMSETN_KR\",\n",
    "    \"FJOR_OMSETN_KR_T1\",\n",
    "    \"TMP_SNITTOMS\",\n",
    "    \"FJOR_SNITTOMS_T1\",\n",
    "    \"TMP_SALGSINT_BED\",\n",
    "    \"TMP_FORBRUK_BED\",\n",
    "    \"VAREKOST_BED\",\n",
    "    \"GJELDENDE_DRIFTSK_KR\",\n",
    "    \"DRIFTSKOST_KR\",\n",
    "    \"FJOR_DRIFTSKOST_KR_T1\",\n",
    "    \"NACEF_5\",\n",
    "    \"SALGSINT\",\n",
    "    \"FORBRUK\",\n",
    "    \"TMP_NO_P4005\",\n",
    "    \"TMP_AVPROS_ORGFORB\",\n",
    "    \"ORGNR_N_1\",\n",
    "    \"TMP_NO_OMSETN\",\n",
    "    \"TMP_DRIFTSKOSTNAD_9010\",\n",
    "    \"TMP_DRIFTSKOSTNAD_9910\",\n",
    "]\n",
    "\n",
    "# # Filter the DataFrame for the specified field values\n",
    "skjema = skjema[skjema[\"feltnavn\"].isin(felt_id_values)]\n",
    "\n",
    "# Pivot the DataFrame\n",
    "skjema = skjema.pivot_table(\n",
    "    index=[\"id\", \"radnr\", \"lopenr\"],\n",
    "    columns=\"feltnavn\",\n",
    "    values=\"feltverdi\",\n",
    "    aggfunc=\"first\",\n",
    ")\n",
    "skjema = skjema.reset_index()\n",
    "skjema.columns = skjema.columns.str.lower()  # Convert column names to lower case\n",
    "\n",
    "skjema = skjema[['orgnr_n_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change option to show all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "skjema.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change option to print all rows\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "skjema['orgnr_n_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g2022/statistiske_foretak_foretak.parquet\"\n",
    "    )\n",
    "    if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Use the ParquetDataset to read multiple files\n",
    "dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "table = dataset.read()\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "skjema = table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skjema.to_parquet(\n",
    "    f\"gs://ssb-prod-noeku-data-delt/statistikkfiler/g2022/statistiske_foretak_foretak.parquet\",\n",
    "    storage_options={\"token\": AuthClient.fetch_google_credentials()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skjema.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Transfer from old bucks to new:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Skjema data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_year = 2017\n",
    "end_year = 2021\n",
    "skjema_list = 'RA-1407'\n",
    "\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    fil_path = [\n",
    "        f\n",
    "        for f in fs.glob(\n",
    "            f\"gs://ssb-prod-noeku-data-produkt/eimerdb/nokubasen/skjemadata/aar={current_year}/skjema={skjema_list}/*\",\n",
    "        )\n",
    "        # if f.endswith(\".parquet\")\n",
    "    ]\n",
    "\n",
    "    # Use the ParquetDataset to read multiple files\n",
    "    if fil_path:\n",
    "        skjema = pd.read_parquet(fil_path[0], filesystem=fs)\n",
    "    \n",
    "    destination_path = f\"gs://ssb-strukt-naering-data-produkt-prod/naringer/inndata/skjemadata/skjema={skjema_list}/aar={year}/skjemadata_data_0.parquet\"\n",
    "    \n",
    "    skjema.to_parquet(destination_path, filesystem=fs, index=False)\n",
    "\n",
    "print(\"Data transfer completed for all years.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# statistikkfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_year = 2023\n",
    "end_year = 2023\n",
    "\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    fil_path = [\n",
    "        f\n",
    "        for f in fs.glob(\n",
    "            f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistikkfil_bedrifter_nr.parquet\",\n",
    "        )\n",
    "        # if f.endswith(\".parquet\")\n",
    "    ]\n",
    "\n",
    "    # Use the ParquetDataset to read multiple files\n",
    "    if fil_path:\n",
    "        skjema = pd.read_parquet(fil_path[0], filesystem=fs)\n",
    "    \n",
    "    destination_path = f\"gs://ssb-strukt-naering-data-produkt-prod/naringer/klargjorte-data/statistikkfiler/aar={year}/statistikkfil_bedrifter_nr.parquet\"\n",
    "    \n",
    "    skjema.to_parquet(destination_path, filesystem=fs, index=False)\n",
    "    \n",
    "    del skjema\n",
    "    \n",
    "    fil_path = [\n",
    "        f\n",
    "        for f in fs.glob(\n",
    "            f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistikkfil_bedrifter_pub.parquet\",\n",
    "        )\n",
    "        # if f.endswith(\".parquet\")\n",
    "    ]\n",
    "\n",
    "    # Use the ParquetDataset to read multiple files\n",
    "    if fil_path:\n",
    "        skjema = pd.read_parquet(fil_path[0], filesystem=fs)\n",
    "    \n",
    "    destination_path = f\"gs://ssb-strukt-naering-data-produkt-prod/naringer/klargjorte-data/statistikkfiler/aar={year}/statistikkfil_bedrifter_pub.parquet\"\n",
    "    \n",
    "    skjema.to_parquet(destination_path, filesystem=fs, index=False)\n",
    "    \n",
    "    del skjema\n",
    "    \n",
    "    fil_path = [\n",
    "        f\n",
    "        for f in fs.glob(\n",
    "            f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistikkfil_foretak_nr.parquet\",\n",
    "        )\n",
    "        # if f.endswith(\".parquet\")\n",
    "    ]\n",
    "\n",
    "    # Use the ParquetDataset to read multiple files\n",
    "    if fil_path:\n",
    "        skjema = pd.read_parquet(fil_path[0], filesystem=fs)\n",
    "    \n",
    "    destination_path = f\"gs://ssb-strukt-naering-data-produkt-prod/naringer/klargjorte-data/statistikkfiler/aar={year}/statistikkfil_foretak_nr.parquet\"\n",
    "    \n",
    "    skjema.to_parquet(destination_path, filesystem=fs, index=False)\n",
    "    \n",
    "    del skjema\n",
    "    \n",
    "    fil_path = [\n",
    "        f\n",
    "        for f in fs.glob(\n",
    "            f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistikkfil_foretak_pub.parquet\",\n",
    "        )\n",
    "        # if f.endswith(\".parquet\")\n",
    "    ]\n",
    "\n",
    "    # Use the ParquetDataset to read multiple files\n",
    "    if fil_path:\n",
    "        skjema = pd.read_parquet(fil_path[0], filesystem=fs)\n",
    "    \n",
    "    destination_path = f\"gs://ssb-strukt-naering-data-produkt-prod/naringer/klargjorte-data/statistikkfiler/aar={year}/statistikkfil_foretak_pub.parquet\"\n",
    "    \n",
    "    skjema.to_parquet(destination_path, filesystem=fs, index=False)\n",
    "    \n",
    "    del skjema\n",
    "\n",
    "print(\"Data transfer completed for all years.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_year = 2022\n",
    "end_year = 2022\n",
    "\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    fil_path = [\n",
    "        f\n",
    "        for f in fs.glob(\n",
    "            f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistiske_foretak_bedrifter.parquet\",\n",
    "        )\n",
    "        # if f.endswith(\".parquet\")\n",
    "    ]\n",
    "\n",
    "    # Use the ParquetDataset to read multiple files\n",
    "    if fil_path:\n",
    "        skjema = pd.read_parquet(fil_path[0], filesystem=fs)\n",
    "    \n",
    "    destination_path = f\"gs://ssb-strukt-naering-data-produkt-prod/naringer/klargjorte-data/statistikkfiler/aar={year}/statistiske_foretak_bedrifter.parquet\"\n",
    "    \n",
    "    skjema.to_parquet(destination_path, filesystem=fs, index=False)\n",
    "    \n",
    "    fil_path = [\n",
    "        f\n",
    "        for f in fs.glob(\n",
    "            f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistikkfil_bedrifter_pub.parquet\",\n",
    "        )\n",
    "        # if f.endswith(\".parquet\")\n",
    "    ]\n",
    "\n",
    "    # Use the ParquetDataset to read multiple files\n",
    "    if fil_path:\n",
    "        skjema = pd.read_parquet(fil_path[0], filesystem=fs)\n",
    "    \n",
    "    destination_path = f\"gs://ssb-strukt-naering-data-produkt-prod/naringer/klargjorte-data/statistikkfiler/aar={year}/statistikkfil_bedrifter_pub.parquet\"\n",
    "    \n",
    "    skjema.to_parquet(destination_path, filesystem=fs, index=False)\n",
    "    \n",
    "    fil_path = [\n",
    "        f\n",
    "        for f in fs.glob(\n",
    "            f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistiske_foretak_foretak.parquet\",\n",
    "        )\n",
    "        # if f.endswith(\".parquet\")\n",
    "    ]\n",
    "\n",
    "    # Use the ParquetDataset to read multiple files\n",
    "    if fil_path:\n",
    "        skjema = pd.read_parquet(fil_path[0], filesystem=fs)\n",
    "    \n",
    "    destination_path = f\"gs://ssb-strukt-naering-data-produkt-prod/naringer/klargjorte-data/statistikkfiler/aar={year}/statistiske_foretak_foretak.parquet\"\n",
    "    \n",
    "    skjema.to_parquet(destination_path, filesystem=fs, index=False)\n",
    "    \n",
    "    fil_path = [\n",
    "        f\n",
    "        for f in fs.glob(\n",
    "            f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{year}/statistikkfil_foretak_pub.parquet\",\n",
    "        )\n",
    "        # if f.endswith(\".parquet\")\n",
    "    ]\n",
    "\n",
    "    # Use the ParquetDataset to read multiple files\n",
    "    if fil_path:\n",
    "        skjema = pd.read_parquet(fil_path[0], filesystem=fs)\n",
    "    \n",
    "    destination_path = f\"gs://ssb-strukt-naering-data-produkt-prod/naringer/klargjorte-data/statistikkfiler/aar={year}/statistikkfil_foretak_pub.parquet\"\n",
    "    \n",
    "    skjema.to_parquet(destination_path, filesystem=fs, index=False)\n",
    "\n",
    "print(\"Data transfer completed for all years.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-noeku-data-produkt/eimerdb/nokubasen/skjemadata/aar=2023/skjema=RA-0174-1/skjemadata_data_0.parquet\",\n",
    "    )\n",
    "    # if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "if fil_path:\n",
    "    skjema = pd.read_parquet(fil_path[0], filesystem=fs)\n",
    "\n",
    "destination_path = f\"gs://ssb-strukt-naering-data-produkt-prod/naringer/inndata/skjemadata/skjema=RA-0174-1/aar=2023/skjemadata_data_0.parquet\"\n",
    "\n",
    "skjema.to_parquet(destination_path, filesystem=fs, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "\n",
    "destination_path = f\"gs://ssb-strukt-naering-data-produkt-prod/naringer/utdata/temp.parquet\"\n",
    "\n",
    "temp.to_parquet(destination_path, filesystem=fs, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"skjema:\", skjema, type(skjema))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
