{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import gcsfs\n",
    "import getpass\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, r2_score\n",
    "import geopandas as gpd\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# import sgis as sg\n",
    "import dapla as dp\n",
    "import datetime\n",
    "from dapla.auth import AuthClient\n",
    "from dapla import FileClient\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import requests\n",
    "from pyjstat import pyjstat\n",
    "# import plotly.express as px\n",
    "from ipywidgets import interact, Dropdown\n",
    "# from klass import search_classification\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../functions\")\n",
    "import kommune_pop\n",
    "import kommune_inntekt\n",
    "import kpi\n",
    "import ao\n",
    "import kommune_translate\n",
    "import kommune\n",
    "\n",
    "fs = FileClient.get_gcs_file_system()\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math\n",
    "\n",
    "# good_df = ao.rette_bedrifter(good_df)\n",
    "\n",
    "import input_data\n",
    "# import create_datafiles\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "import time\n",
    "import create_datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_classification()\n",
    "\n",
    "year = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "current_year_good_oms, current_year_bad_oms, v_orgnr_list_for_imputering, training_data, imputatable_df, time_series_df = create_datafiles.main(year, 0.65)\n",
    "\n",
    "processing_time = time.time() - start_time\n",
    "print(f\"Time taken to create training data: {processing_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Fix Early Stopping/ implement flexible learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def knn_model(training_df, scaler, df_estimeres, GridSearch=True):\n",
    "    \n",
    "    df = training_df.copy()\n",
    "    imputed_df = df_estimeres.copy()\n",
    "\n",
    "    columns_to_fill = [\"nacef_5\", \"tmp_sn2007_5\", \"b_kommunenr\"]\n",
    "    numeric_columns_to_fill = [\n",
    "        \"inntekt_delta_oms\",\n",
    "        \"emp_delta_oms\",\n",
    "        \"befolkning_delta_oms\",\n",
    "        \"inflation_rate_oms\",\n",
    "        \"gjeldende_bdr_syss\",\n",
    "        \"new_oms_trendForecast\",\n",
    "        'oms_syssmean_basedOn_naring',\n",
    "        'oms_syssmean_basedOn_naring_kommune'\n",
    "    ]\n",
    "\n",
    "    # Fill NaN values with 'missing' for the specified columns\n",
    "    df[columns_to_fill] = df[columns_to_fill].fillna('missing')\n",
    "    imputed_df[columns_to_fill] = imputed_df[columns_to_fill].fillna('missing')\n",
    "    \n",
    "    df[numeric_columns_to_fill] = df[numeric_columns_to_fill].fillna(0)\n",
    "    imputed_df[numeric_columns_to_fill] = imputed_df[numeric_columns_to_fill].fillna(0)\n",
    "\n",
    "    categorical_columns = [\"nacef_5\", \"tmp_sn2007_5\", \"b_kommunenr\"]\n",
    "    for col in categorical_columns:\n",
    "        df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    X = df.drop(columns=[\"new_oms\"])\n",
    "    y = df[\"new_oms\"]\n",
    "\n",
    "    categorical_features = [\"nacef_5\", \"tmp_sn2007_5\", \"b_kommunenr\"]\n",
    "    numerical_features = [\n",
    "        \"inntekt_delta_oms\",\n",
    "        \"emp_delta_oms\",\n",
    "        \"befolkning_delta_oms\",\n",
    "        \"inflation_rate_oms\",\n",
    "        \"gjeldende_bdr_syss\",\n",
    "        \"new_oms_trendForecast\",\n",
    "        'oms_syssmean_basedOn_naring',\n",
    "        'oms_syssmean_basedOn_naring_kommune'\n",
    "    ]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", scaler, numerical_features),\n",
    "            (\"cat\", OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\"), categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    preprocessor.fit(X_train)\n",
    "    X_train_transformed = preprocessor.transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "    if GridSearch:\n",
    "        # Define the model\n",
    "        regressor = KNeighborsRegressor()\n",
    "\n",
    "        # Define parameter grid for GridSearch\n",
    "        param_grid = {\n",
    "            'n_neighbors': [2, 3, 5, 7]\n",
    "        }\n",
    "\n",
    "        # Grid search with cross-validation\n",
    "        grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, verbose=1)\n",
    "        grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "        # Print best parameters\n",
    "        print(\"Best parameters found by GridSearch:\", grid_search.best_params_)\n",
    "\n",
    "        # Use best estimator from grid search\n",
    "        regressor = grid_search.best_estimator_\n",
    "    else:\n",
    "        # Define the model with default parameters\n",
    "        regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "        # Train the model\n",
    "        regressor.fit(X_train_transformed, y_train)\n",
    "\n",
    "    y_pred = regressor.predict(X_test_transformed)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r_squared = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"R-squared:\", r_squared)\n",
    "    print(\"Mean Absolute Error:\", mae)\n",
    "    \n",
    "    # Plot Predicted vs. Actual Values\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\", lw=2)\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(\"Predicted vs. Actual Values\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Residuals\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(y_test, residuals, alpha=0.3)\n",
    "    plt.hlines(0, y_test.min(), y_test.max(), colors=\"r\", linestyles=\"dashed\")\n",
    "    plt.xlabel(\"Actual\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.title(\"Residuals Plot\")\n",
    "    plt.show()\n",
    "\n",
    "    imputed_X = imputed_df.drop(columns=[\"new_oms\"])\n",
    "    imputed_X_transformed = preprocessor.transform(imputed_X)\n",
    "    imputed_df[\"predicted_oms\"] = regressor.predict(imputed_X_transformed)\n",
    "    \n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = knn_model(training_data, RobustScaler(), imputatable_df, GridSearch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort predicted_oms from smallest to larges\n",
    "test = imputed_df.copy()\n",
    "test.sort_values(by=\"predicted_oms\", ascending=True, inplace=True)\n",
    "\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_to_merge = imputed_df[['v_orgnr', 'year', 'b_kommunenr', 'orgnr_foretak', 'naring', 'predicted_oms']]\n",
    "df_to_merge = imputed_df[['v_orgnr', 'year', 'id', 'predicted_oms']]\n",
    "# df_to_merge.rename(columns={'orgnr_foretak': 'orgnr_n_1', 'naring':'tmp_sn2007_5'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_to_merge.copy()\n",
    "test.sort_values(by=\"predicted_oms\", ascending=True, inplace=True)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_df = pd.merge(current_year_bad_oms, df_to_merge, on=['v_orgnr', 'id', 'year'], how='left')\n",
    "\n",
    "test = bad_df.copy()\n",
    "test.sort_values(by=\"predicted_oms\", ascending=True, inplace=True)\n",
    "\n",
    "# change pd option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bad_df[(bad_df['predicted_oms'].isnull() | np.isinf(bad_df['predicted_oms']))]\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bad_df['new_oms'] = bad_df['predicted_oms']\n",
    "\n",
    "bad_df.drop(['predicted_oms'], axis=1, inplace=True)\n",
    "\n",
    "good_df = pd.concat([current_year_good_oms, bad_df], ignore_index=True)\n",
    "\n",
    "# filter out good_df so that lopenr == 1\n",
    "good_df = good_df[good_df['lopenr'] == 1]\n",
    "\n",
    "print(good_df.shape)\n",
    "\n",
    "# if 'new_oms' is less than 0 then 'new_oms' = 0\n",
    "good_df['new_oms'] = good_df['new_oms'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "\n",
    "good_df.drop(['tot_oms_fordelt'], axis=1, inplace=True)\n",
    "\n",
    "good_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = good_df.copy()\n",
    "test.sort_values(by=\"new_oms\", ascending=True, inplace=True)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group by 'id' and calculate the sum\n",
    "grouped = (\n",
    "    good_df.groupby(\"id\")[[\"new_oms\"]].sum().reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "grouped.rename(\n",
    "    columns={\"new_oms\": \"tot_oms_fordelt\"},\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the grouped DataFrame back to the original DataFrame based on 'id'\n",
    "good_df = pd.merge(good_df, grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "good_df['oms_share'] = good_df['new_oms'] / good_df['tot_oms_fordelt']\n",
    "\n",
    "# drop 'new_oms' column\n",
    "good_df.drop(['new_oms', 'tot_oms_fordelt'], axis=1, inplace=True)\n",
    "\n",
    "good_df[\"oms_share\"].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "good_df['oms_share'].fillna(0, inplace=True)\n",
    "\n",
    "good_df['new_oms'] = good_df['oms_share'] * good_df['foretak_omsetning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### TEST\n",
    "test_grouped = (\n",
    "    good_df.groupby(\"id\")[[\"new_oms\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "test_grouped.rename(\n",
    "    columns={\"new_oms\": \"test_tot_oms_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "test = pd.merge(good_df, test_grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "# Convert to integers\n",
    "good_df['foretak_omsetning'] = good_df['foretak_omsetning'].astype(float).round().astype(int)\n",
    "good_df['new_oms'] = good_df['new_oms'].astype(float).round().astype(int)\n",
    "\n",
    "test['oms_diff'] = test['foretak_omsetning'] - test['test_tot_oms_fordelt']\n",
    "\n",
    "# filter test for results where oms_diff is not 0\n",
    "test = test[test['oms_diff'] != 0]\n",
    "\n",
    "test['oms_diff'] = test['oms_diff'].abs()\n",
    "\n",
    "# Step 2: Sort the DataFrame by oms_diff in descending order\n",
    "test_sorted = test.sort_values(by='oms_diff', ascending=False)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_df['id'] = good_df['id'].astype(str)\n",
    "good_df['nacef_5'] = good_df['nacef_5'].astype(str)\n",
    "good_df['orgnr_n_1'] = good_df['orgnr_n_1'].astype(str)\n",
    "good_df['b_kommunenr'] = good_df['b_kommunenr'].astype(str)\n",
    "good_df['forbruk'] = good_df['forbruk'].astype(float)\n",
    "good_df['salgsint'] = good_df['salgsint'].astype(float)\n",
    "good_df['tmp_no_p4005'] = good_df['tmp_no_p4005'].astype(float)\n",
    "good_df['foretak_omsetning'] = good_df['foretak_omsetning'].astype(float)\n",
    "\n",
    "# good_df['geometry'] = good_df['geometry'].apply(lambda geom: geom.wkt if geom is not None else None)\n",
    "\n",
    "good_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_df.to_parquet(\n",
    "    f\"gs://ssb-prod-noeku-data-produkt/temp/knn_varehandel.parquet\",\n",
    "    storage_options={\"token\": AuthClient.fetch_google_credentials()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-noeku-data-produkt/temp/knn_varehandel.parquet\"\n",
    "    )\n",
    "    if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Use the ParquetDataset to read multiple files\n",
    "dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "table = dataset.read()\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "good_df = table.to_pandas()\n",
    "\n",
    "# count how many rows where tot_driftskost_fordelt is NaN\n",
    "print(good_df['tot_driftskost_fordelt'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "condition = (good_df['foretak_omsetning'] == 0) | (good_df['foretak_driftskostnad'] == 0)\n",
    "\n",
    "# Drop the rows that meet the condition\n",
    "good_df = good_df[~condition]\n",
    "\n",
    "good_df[\"gjeldende_driftsk_kr\"] = pd.to_numeric(good_df[\"gjeldende_driftsk_kr\"], errors=\"coerce\")\n",
    "good_df[\"b_sysselsetting_syss\"] = pd.to_numeric(good_df[\"b_sysselsetting_syss\"], errors=\"coerce\")\n",
    "\n",
    "good_df.drop(['tot_driftskost_fordelt'], axis=1, inplace=True)\n",
    "\n",
    "good_df[\"driftsk\"] = good_df[\"gjeldende_driftsk_kr\"]\n",
    "\n",
    "grouped = (\n",
    "    good_df.groupby(\"id\")[[\"driftsk\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "grouped.rename(\n",
    "    columns={\"driftsk\": \"tot_driftskost_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "good_df = pd.merge(good_df, grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "# Convert columns to numeric\n",
    "good_df[\"tot_driftskost_fordelt\"] = pd.to_numeric(\n",
    "    good_df[\"tot_driftskost_fordelt\"], errors=\"coerce\"\n",
    ")\n",
    "good_df[\"driftsk\"] = pd.to_numeric(good_df[\"driftsk\"], errors=\"coerce\")\n",
    "\n",
    "good_df[\"b_sysselsetting_syss\"] = pd.to_numeric(good_df[\"b_sysselsetting_syss\"], errors=\"coerce\")\n",
    "\n",
    "# Convert 'lonn' to numeric, replacing comma with dot and handling errors\n",
    "good_df[\"lonn\"] = good_df[\"lonn\"].str.replace(',', '.').astype(float)\n",
    "good_df[\"lonn\"] = good_df[\"lonn\"] / 100\n",
    "\n",
    "# Calculate drkost_share\n",
    "# Calculate drkost_share\n",
    "good_df[\"drkost_share\"] = good_df.apply(\n",
    "    lambda row: row[\"lonn\"] if row[\"foretak_driftskostnad\"] != 0 and row[\"tot_driftskost_fordelt\"] == 0 else (row[\"driftsk\"] / row[\"tot_driftskost_fordelt\"] if row[\"tot_driftskost_fordelt\"] != 0 else np.nan),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Handle any NaN or inf values in drkost_share\n",
    "good_df['drkost_share'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "good_df['drkost_share'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate total b_sysselsetting_syss per id\n",
    "good_df['total_syss'] = good_df.groupby('id')['b_sysselsetting_syss'].transform('sum')\n",
    "\n",
    "good_df[\"total_syss\"] = pd.to_numeric(good_df[\"total_syss\"], errors=\"coerce\")\n",
    "\n",
    "# Calculate the share of b_sysselsetting_syss per id\n",
    "good_df['syss_share'] = good_df['b_sysselsetting_syss'] / good_df['total_syss']\n",
    "\n",
    "# Update drkost_share for the specified conditions\n",
    "good_df.loc[\n",
    "    (good_df['tot_driftskost_fordelt'] == 0) & \n",
    "    (good_df['drkost_share'] == 0) & \n",
    "    (good_df['foretak_driftskostnad'] != 0), \n",
    "    'drkost_share'\n",
    "] = good_df['syss_share']\n",
    "\n",
    "# Round drkost_share to 10 decimal points\n",
    "good_df['drkost_share'] = good_df['drkost_share'].round(10)\n",
    "\n",
    "\n",
    "# Calculate new_drkost\n",
    "good_df[\"new_drkost\"] = good_df[\"drkost_share\"] * good_df[\"foretak_driftskostnad\"]\n",
    "\n",
    "# Replace NaN in new_drkost with gjeldende_driftsk_kr\n",
    "good_df[\"new_drkost\"].fillna(good_df[\"gjeldende_driftsk_kr\"], inplace=True)\n",
    "good_df['new_drkost'] = good_df['new_drkost'].astype(float)\n",
    "\n",
    "# if foretak_driftskostnad = 0 then new_drkost = 0\n",
    "good_df.loc[good_df['foretak_driftskostnad'] == 0, 'new_drkost'] = 0\n",
    "\n",
    "# if foretak_omsetning = 0 then new_oms = 0\n",
    "good_df.loc[good_df['foretak_omsetning'] == 0, 'new_oms'] = 0\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "# good_df.drop(['tot_driftskost_fordelt', 'drkost_share'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### TEST\n",
    "test_grouped = (\n",
    "    good_df.groupby(\"id\")[[\"new_drkost\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "test_grouped.rename(\n",
    "    columns={\"new_drkost\": \"test_tot_drkost_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "test = pd.merge(good_df, test_grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "test['drkost_diff'] = test['foretak_driftskostnad'] - test['test_tot_drkost_fordelt']\n",
    "\n",
    "test = test.sort_values(by='drkost_diff', ascending=True)\n",
    "\n",
    "# change pd option to show all rows \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped = (\n",
    "    good_df.groupby(\"id\")[[\"new_oms\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "grouped.rename(\n",
    "    columns={\"new_oms\": \"tot_oms_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "good_df = pd.merge(good_df, grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "mask_regtype_04 = good_df['regtype'] == '04'\n",
    "mask_regtype_not_04 = good_df['regtype'] != '04'\n",
    "\n",
    "# Step 2: Update new_oms where regtype is '04'\n",
    "good_df.loc[mask_regtype_04, 'new_oms'] = good_df.loc[mask_regtype_04, 'new_drkost']\n",
    "\n",
    "# Step 2: Group by 'id' and sum 'new_oms' where regtype is '04'\n",
    "total_helper_oms = good_df.loc[mask_regtype_04].groupby('id')['new_oms'].sum().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# Rename the aggregated 'new_oms' to 'new_oms_total_helper' for clarity\n",
    "total_helper_oms.rename(columns={'new_oms': 'new_oms_total_helper'}, inplace=True)\n",
    "\n",
    "# Step 3: Merge the aggregated result back into the original DataFrame\n",
    "good_df = pd.merge(good_df, total_helper_oms, on='id', how='left', suffixes=('', '_total_helper'))\n",
    "\n",
    "# Reset index to ensure it's unique\n",
    "good_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert 'foretak_omsetning' to numeric, setting errors to NaN\n",
    "good_df['foretak_omsetning'] = pd.to_numeric(good_df['foretak_omsetning'], errors='coerce')\n",
    "\n",
    "# Fill NaN values that might have been introduced by conversion errors\n",
    "good_df['foretak_omsetning'].fillna(0, inplace=True)\n",
    "good_df['new_oms_total_helper'].fillna(0, inplace=True)\n",
    "\n",
    "good_df['new_oms_total_helper'] = pd.to_numeric(good_df['new_oms_total_helper'], errors='coerce')\n",
    "\n",
    "# Step 4: Subtract 'new_oms_total_helper' from 'foretak_omsetning'\n",
    "good_df['total_rest_oms'] = good_df['foretak_omsetning'] - good_df['new_oms_total_helper']\n",
    "\n",
    "# Step 2: Group by 'id' and sum 'new_oms' where regtype is not '04'\n",
    "total_non_helper_oms = good_df.loc[mask_regtype_not_04].groupby('id')['new_oms'].sum().reset_index()\n",
    "\n",
    "# Step 3: Merge the aggregated result back into the original DataFrame\n",
    "good_df = pd.merge(good_df, total_non_helper_oms, on='id', how='left', suffixes=('', '_total_non_helper'))\n",
    "\n",
    "good_df['new_oms_total_non_helper'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# test 4\n",
    "\n",
    "# Convert 'new_oms' and 'new_oms_total_non_helper' to numeric, coercing errors to NaN\n",
    "good_df['new_oms'] = pd.to_numeric(good_df['new_oms'], errors='coerce')\n",
    "good_df['new_oms_total_non_helper'] = pd.to_numeric(good_df['new_oms_total_non_helper'], errors='coerce')\n",
    "\n",
    "# convert Nan in new_oms_total_non_helper to 0\n",
    "good_df['new_oms_total_non_helper'].fillna(0, inplace=True)\n",
    "\n",
    "## Here we need to add some stuff\n",
    "# Calculate total lonn per id excluding regtype '04'\n",
    "good_df['total_lonn_non_04'] = good_df[mask_regtype_not_04].groupby('id')['lonn'].transform('sum')\n",
    "\n",
    "# Ensure total_lonn_non_04 is numeric and handle any conversion issues\n",
    "good_df['total_lonn_non_04'] = pd.to_numeric(good_df['total_lonn_non_04'], errors='coerce')\n",
    "\n",
    "# Recalculate lonn for non-'04' rows to sum to 100% per id\n",
    "good_df['lonn_non_04_share'] = np.where(\n",
    "    mask_regtype_not_04,\n",
    "    good_df['lonn'] / good_df['total_lonn_non_04'],\n",
    "    0\n",
    ")\n",
    "\n",
    "good_df['lonn_non_04_share'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate total b_sysselsetting_syss per id excluding regtype '04'\n",
    "good_df['total_syss_non_04'] = good_df[mask_regtype_not_04].groupby('id')['b_sysselsetting_syss'].transform('sum')\n",
    "\n",
    "# Calculate the share of b_sysselsetting_syss excluding regtype '04'\n",
    "good_df['syss_share_non_04'] = good_df['b_sysselsetting_syss'] / good_df['total_syss_non_04']\n",
    "\n",
    "good_df['syss_share_non_04'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate oms_share_non_helpers with the new condition\n",
    "good_df['oms_share_non_helpers'] = good_df.apply(\n",
    "    lambda row: 1 if row['total_rest_oms'] == 0 else (\n",
    "        row['lonn_non_04_share'] if row['foretak_omsetning'] != 0 and row['tot_oms_fordelt'] == 0 else (\n",
    "            row[\"new_oms\"] / row[\"new_oms_total_non_helper\"] if row[\"new_oms_total_non_helper\"] != 0 else row['syss_share_non_04'])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "######################################\n",
    "\n",
    "# Handle any NaN or inf values in oms_share_non_helpers\n",
    "good_df['oms_share_non_helpers'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "good_df['oms_share_non_helpers'].fillna(0, inplace=True)\n",
    "\n",
    "# Ensure oms_share_non_helpers is set to 0 where regtype is '04'\n",
    "good_df.loc[good_df['regtype'] == '04', 'oms_share_non_helpers'] = 0\n",
    "\n",
    "# Finally, update new_oms with the calculated oms_share_non_helpers\n",
    "good_df['new_oms'] = np.where(good_df['regtype'] == '04', \n",
    "                              good_df['new_oms'], \n",
    "                              good_df['oms_share_non_helpers'] * good_df['total_rest_oms'])\n",
    "\n",
    "# Drop any temporary or helper columns if necessary\n",
    "# good_df.drop(['total_lonn_non_04', 'total_syss_non_04', 'lonn_non_04_share'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "## end new code\n",
    "\n",
    "# old code\n",
    "# good_df['oms_share_non_helpers'] = good_df['new_oms'] / good_df['new_oms_total_non_helper']\n",
    "\n",
    "# # Set the oms_share_non_helpers to 0 where regtype is '04'\n",
    "# good_df.loc[good_df['regtype'] == '04', 'oms_share_non_helpers'] = 0\n",
    "\n",
    "# # Replace NaN in 'oms_share_non_helpers' resulting from division by zero or NaN in the denominator\n",
    "# good_df['oms_share_non_helpers'].fillna(0, inplace=True)\n",
    "\n",
    "# # Optionally, replace NaN resulting from any remaining errors with a default value\n",
    "# good_df.fillna(0, inplace=True)\n",
    "\n",
    "# # Step 1: Use numpy.where to conditionally update new_oms\n",
    "# good_df['new_oms'] = np.where(good_df['regtype'] == '04', \n",
    "#                               good_df['new_oms'], \n",
    "#                               good_df['oms_share_non_helpers'] * good_df['total_rest_oms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### TEST\n",
    "\n",
    "test_grouped = (\n",
    "    good_df.groupby(\"id\")[[\"new_oms\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "test_grouped.rename(\n",
    "    columns={\"new_oms\": \"test_tot_oms_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "test = pd.merge(good_df, test_grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "test['oms_diff'] = test['foretak_omsetning'] - test['test_tot_oms_fordelt']\n",
    "\n",
    "test = test.sort_values(by='oms_diff', ascending=False)\n",
    "\n",
    "# change pd option to show all rows \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "test.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "# Define the values for w_naring_vh, w_nace1_ikke_vh, and w_nace2_ikke_vh\n",
    "w_naring_vh = (\"45\", \"46\", \"47\")\n",
    "w_nace1_ikke_vh = \"45.403\"\n",
    "w_nace2_ikke_vh = (\"45.2\", \"46.1\")\n",
    "\n",
    "enhetene_brukes = good_df.copy()\n",
    "\n",
    "# Filter the DataFrame based on conditions and create vhbed variable\n",
    "enhetene_brukes[\"vhbed\"] = 0\n",
    "\n",
    "# Check if the first two characters of 'naring' are in w_naring_vh\n",
    "enhetene_brukes.loc[\n",
    "    enhetene_brukes[\"tmp_sn2007_5\"].str[:2].isin(w_naring_vh), \"vhbed\"\n",
    "] = 1\n",
    "\n",
    "# Check if 'naring' is in w_nace1_ikke_vh\n",
    "enhetene_brukes.loc[enhetene_brukes[\"tmp_sn2007_5\"] == w_nace1_ikke_vh, \"vhbed\"] = 0\n",
    "\n",
    "# Check if the first four characters of 'naring' are in w_nace2_ikke_vh\n",
    "enhetene_brukes.loc[\n",
    "    enhetene_brukes[\"tmp_sn2007_5\"].str[:4].isin(w_nace2_ikke_vh), \"vhbed\"\n",
    "] = 0\n",
    "\n",
    "enhetene_brukes = enhetene_brukes.drop_duplicates(subset=[\"orgnr_n_1\", \"lopenr\", \"radnr\", \"v_orgnr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aar = 2021\n",
    "\n",
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{aar}/statistikkfil_foretak_nr.parquet\"\n",
    "    )\n",
    "    if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Use the ParquetDataset to read multiple files\n",
    "dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "table = dataset.read()\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "foretak = table.to_pandas()\n",
    "\n",
    "\n",
    "\n",
    "foretak = foretak[[\"enhets_id\",'orgnr_foretak','nopost_p4295','nopost_p4295','nopost_p4995','nopost_p6200', 'naring_f', 'reg_type', 'nopost_p4005']]\n",
    "\n",
    "# filter for where substr first 2 characters of naring_f is in 45, 46 or 47\n",
    "foretak = foretak[foretak['naring_f'].str[:2].isin(['45', '46', '47'])]\n",
    "\n",
    "# rename columns\n",
    "foretak.rename(\n",
    "    columns={\n",
    "        \"naring_f\": \"foretaksnaring\",\n",
    "        \"enhets_id\": \"id\",\n",
    "        \"nopost_p4295\": \"no4295_f\",\n",
    "        \"nopost_p4995\": \"no4995_f\",\n",
    "        \"nopost_p6200\": \"no6200_f\",\n",
    "        \"nopost_p4005\": \"forbruk_f\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "foretak = foretak[[\"id\", \"forbruk_f\"]]\n",
    "\n",
    "# drop duplicate orgnr_foretak and reset index\n",
    "foretak = foretak.drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "foretak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enhetene_brukes = enhetene_brukes.merge(foretak, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enhetene_brukes ['check'] = enhetene_brukes[\"foretak_driftskostnad\"] - enhetene_brukes[\"forbruk\"]\n",
    "\n",
    "# if check is negative, then 'forbruk' = 'forbruk' / 1000\n",
    "enhetene_brukes ['forbruk'] = np.where(\n",
    "    enhetene_brukes['check'] < 0, enhetene_brukes['forbruk'] / 1000, enhetene_brukes['forbruk']\n",
    ")\n",
    "enhetene_brukes ['check'] = enhetene_brukes[\"foretak_driftskostnad\"] - enhetene_brukes[\"forbruk\"]\n",
    "# print out the count number of rows where check is negative\n",
    "print(enhetene_brukes[enhetene_brukes['check'] < 0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enhetene_brukes['forbruk'] = np.where(\n",
    "    enhetene_brukes['check'] < 0, enhetene_brukes['forbruk_f'], enhetene_brukes['forbruk']\n",
    ")\n",
    "enhetene_brukes ['check'] = enhetene_brukes[\"foretak_driftskostnad\"] - enhetene_brukes[\"forbruk\"]\n",
    "# print out the count number of rows where check is negative\n",
    "print(enhetene_brukes[enhetene_brukes['check'] < 0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enhetene_brukes.head()\n",
    "\n",
    "check = enhetene_brukes[enhetene_brukes['id'] == '11520914']\n",
    "check.head()\n",
    "70231\n",
    "2251296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "salgsint_forbruk = enhetene_brukes[\n",
    "    [\n",
    "        \"orgnr_n_1\",\n",
    "        \"lopenr\",\n",
    "        \"v_orgnr\",\n",
    "        \"forbruk\",\n",
    "        \"salgsint\",\n",
    "        \"radnr\",\n",
    "        \"nacef_5\",\n",
    "        \"tmp_sn2007_5\",\n",
    "        \"new_oms\",\n",
    "        \"vhbed\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "salgsint_forbruk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3\n",
    "\n",
    "har = salgsint_forbruk[salgsint_forbruk.groupby(\"orgnr_n_1\")[\"vhbed\"].transform(\"any\")]\n",
    "# Extract the 'orgnr_n_1' column\n",
    "har = har[[\"orgnr_n_1\"]]\n",
    "\n",
    "# Remove duplicates\n",
    "har.drop_duplicates(inplace=True)\n",
    "\n",
    "har.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4\n",
    "\n",
    "ikke_har = salgsint_forbruk[\n",
    "    ~salgsint_forbruk.groupby(\"orgnr_n_1\")[\"vhbed\"].transform(\"any\")\n",
    "]\n",
    "ikke_har = ikke_har[[\"orgnr_n_1\"]]\n",
    "ikke_har.drop_duplicates(inplace=True)\n",
    "\n",
    "ikke_har[\"ikkevbed\"] = 1\n",
    "\n",
    "ikke_har.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5\n",
    "\n",
    "\n",
    "# Merge ikke_har into salgsint_forbruk with a left join on the 'id' column\n",
    "salgsint_forbruk_update1 = pd.merge(\n",
    "    salgsint_forbruk, ikke_har, on=\"orgnr_n_1\", how=\"left\"\n",
    ")\n",
    "\n",
    "# salgsint_forbruk_update1['ikkevbed'].fillna(0, inplace=True)\n",
    "\n",
    "# Update 'vhbed' to 1 where 'ikkevbed' is 1\n",
    "salgsint_forbruk_update1.loc[salgsint_forbruk_update1[\"ikkevbed\"] == 1, \"vhbed\"] = 1\n",
    "\n",
    "salgsint_forbruk_update1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6\n",
    "# Assuming your original DataFrame is named salgsint_forbruk_update1\n",
    "# Replace 'new_oms', 'orgnr_foretak', 'lopnr', 'vhbed' with the actual column names in your DataFrame\n",
    "\n",
    "# Create sum1 DataFrame for vhbed=1\n",
    "sum1 = (\n",
    "    salgsint_forbruk_update1[salgsint_forbruk_update1[\"vhbed\"] == 1]\n",
    "    .groupby([\"orgnr_n_1\", \"lopenr\"])[\"new_oms\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "sum1.rename(columns={\"new_oms\": \"sumoms_vh\"}, inplace=True)\n",
    "\n",
    "# Create sum2 DataFrame for vhbed=0\n",
    "sum2 = (\n",
    "    salgsint_forbruk_update1[salgsint_forbruk_update1[\"vhbed\"] == 0]\n",
    "    .groupby([\"orgnr_n_1\", \"lopenr\"])[\"new_oms\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "sum2.rename(columns={\"new_oms\": \"sumoms_andre\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "salgsint_forbruk_update1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform an outer join of sum1 and sum2 by 'orgnr_foretak' and 'lopnr'\n",
    "sum3 = pd.merge(sum1, sum2, on=[\"orgnr_n_1\", \"lopenr\"], how=\"outer\")\n",
    "sum3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 8\n",
    "\n",
    "salgsint_forbruk_update2 = pd.merge(\n",
    "    salgsint_forbruk_update1, sum3, on=[\"orgnr_n_1\", \"lopenr\"], how=\"outer\"\n",
    ")\n",
    "salgsint_forbruk_update2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 9 & 10\n",
    "# Assuming 'orgnr_n_1', 'lopenr', and 'rad_nr' are the actual column names\n",
    "# Replace them with the actual names in your DataFrame\n",
    "\n",
    "# Sort the DataFrame by 'orgnr_n_1', 'lopenr', and 'rad_nr'\n",
    "salgsint_forbruk_update2.sort_values(by=[\"orgnr_n_1\", \"lopenr\", \"radnr\"], inplace=True)\n",
    "\n",
    "salgsint_forbruk_update2.sort_values(by=[\"orgnr_n_1\", \"lopenr\", \"vhbed\"], inplace=True)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "salgsint_forbruk_update2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 11\n",
    "\n",
    "# Assuming your DataFrame is named salgsint_forbruk\n",
    "# Replace 'orgnr_foretak', 'lopenr', 'vhbed', 'vhf' with the actual column names\n",
    "\n",
    "# Sort the DataFrame by 'orgnr_foretak' and 'lopenr'\n",
    "\n",
    "salgsint_forbruk_update3 = salgsint_forbruk_update2.copy()\n",
    "\n",
    "salgsint_forbruk_update3.sort_values(by=[\"orgnr_n_1\", \"lopenr\"], inplace=True)\n",
    "\n",
    "# Create a new variable 'vhf' based on the values of 'vhbed'\n",
    "salgsint_forbruk_update3[\"vhf\"] = salgsint_forbruk_update3.groupby(\n",
    "    [\"orgnr_n_1\", \"lopenr\"]\n",
    ")[\"vhbed\"].transform(\"first\")\n",
    "\n",
    "# Retain the value of 'vhf' from the first observation in each group\n",
    "salgsint_forbruk_update3[\"vhf\"] = salgsint_forbruk_update3.groupby(\n",
    "    [\"orgnr_n_1\", \"lopenr\"]\n",
    ")[\"vhf\"].transform(\"first\")\n",
    "\n",
    "# Apply labels to the variables\n",
    "salgsint_forbruk_update3[\"vhbed\"] = salgsint_forbruk_update3[\"vhbed\"].astype(str)\n",
    "salgsint_forbruk_update3[\"vhf\"] = salgsint_forbruk_update3[\"vhf\"].astype(str)\n",
    "\n",
    "label_map_vhbed = {\"1\": \"varehandelsbedrift\", \"0\": \"annen type bedrift\"}\n",
    "label_map_vhf = {\n",
    "    \"1\": \"foretaket har kun varehandelsbedrifter eller ingen\",\n",
    "    \"0\": \"har varehandel og annen bedrift (blandingsnÃ¦ringer)\",\n",
    "}\n",
    "\n",
    "salgsint_forbruk_update3[\"vhbed\"] = salgsint_forbruk_update3[\"vhbed\"].map(\n",
    "    label_map_vhbed\n",
    ")\n",
    "salgsint_forbruk_update3[\"vhf\"] = salgsint_forbruk_update3[\"vhf\"].map(label_map_vhf)\n",
    "\n",
    "salgsint_forbruk_update3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 11\n",
    "\n",
    "# Assuming your DataFrame is named salgsint_forbruk\n",
    "# Replace 'vhf' with the actual name of your column\n",
    "\n",
    "# Filter rows where vhf is 'foretaket har kun varehandelsbedrifter eller ingen'\n",
    "vhf_condition = (\n",
    "    salgsint_forbruk_update3[\"vhf\"]\n",
    "    == \"foretaket har kun varehandelsbedrifter eller ingen\"\n",
    ")\n",
    "vhf_df = salgsint_forbruk_update3.loc[vhf_condition]\n",
    "\n",
    "# Filter rows where vhf is not 'foretaket har kun varehandelsbedrifter eller ingen'\n",
    "andre_df = salgsint_forbruk_update3.loc[~vhf_condition]\n",
    "\n",
    "print(vhf_df.shape)\n",
    "print(andre_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 12\n",
    "\n",
    "vhf_df[\"nokkel\"] = vhf_df[\"new_oms\"] / vhf_df[\"sumoms_vh\"]\n",
    "\n",
    "# Convert 'salgsint' column to numeric\n",
    "vhf_df[\"salgsint\"] = pd.to_numeric(vhf_df[\"salgsint\"], errors=\"coerce\")\n",
    "vhf_df[\"forbruk\"] = pd.to_numeric(vhf_df[\"forbruk\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "vhf_df[\"bedr_salgsint\"] = round(vhf_df[\"salgsint\"] * vhf_df[\"nokkel\"])\n",
    "vhf_df[\"bedr_forbruk\"] = round(vhf_df[\"forbruk\"] * vhf_df[\"nokkel\"])\n",
    "\n",
    "vhf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 13\n",
    "\n",
    "andre_df[\"forbruk\"] = pd.to_numeric(andre_df[\"forbruk\"], errors=\"coerce\")\n",
    "andre_df[\"salgsint\"] = pd.to_numeric(andre_df[\"salgsint\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# Assuming 'andre' is your DataFrame\n",
    "andre_df[\"avanse\"] = andre_df[\"forbruk\"] / andre_df[\"salgsint\"]\n",
    "\n",
    "# Filter rows where vhbed is 1\n",
    "vh_bedriftene = andre_df[andre_df[\"vhbed\"] == \"varehandelsbedrift\"].copy()\n",
    "\n",
    "# Calculate 'nokkel', 'bedr_salgsint', and 'bedr_forbruk' for vh-bedriftene\n",
    "vh_bedriftene[\"nokkel\"] = vh_bedriftene[\"new_oms\"] / vh_bedriftene[\"sumoms_vh\"]\n",
    "vh_bedriftene[\"bedr_salgsint\"] = round(\n",
    "    vh_bedriftene[\"salgsint\"] * vh_bedriftene[\"nokkel\"]\n",
    ")\n",
    "vh_bedriftene.loc[\n",
    "    vh_bedriftene[\"bedr_salgsint\"] > vh_bedriftene[\"new_oms\"], \"bedr_salgsint\"\n",
    "] = vh_bedriftene[\"new_oms\"]\n",
    "vh_bedriftene[\"bedr_forbruk\"] = round(\n",
    "    vh_bedriftene[\"bedr_salgsint\"] * vh_bedriftene[\"avanse\"]\n",
    ")\n",
    "\n",
    "# Summarize vh-bedriftene\n",
    "brukt1 = (\n",
    "    vh_bedriftene.groupby([\"orgnr_n_1\", \"lopenr\"])\n",
    "    .agg({\"bedr_salgsint\": \"sum\", \"bedr_forbruk\": \"sum\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge summarized values back to 'andre'\n",
    "andre = pd.merge(andre_df, brukt1, on=[\"orgnr_n_1\", \"lopenr\"], how=\"left\")\n",
    "\n",
    "# Calculate 'resten1' and 'resten2'\n",
    "andre[\"resten1\"] = andre[\"salgsint\"] - andre[\"bedr_salgsint\"]\n",
    "andre[\"resten2\"] = andre[\"forbruk\"] - andre[\"bedr_forbruk\"]\n",
    "\n",
    "# Filter rows where vhbed is not 1\n",
    "blanding_av_vh_og_andre = andre[andre[\"vhbed\"] != \"varehandelsbedrift\"].copy()\n",
    "\n",
    "# Calculate 'nokkel', 'bedr_salgsint', and 'bedr_forbruk' for blending of vh and other industries\n",
    "blanding_av_vh_og_andre[\"nokkel\"] = (\n",
    "    blanding_av_vh_og_andre[\"new_oms\"] / blanding_av_vh_og_andre[\"sumoms_andre\"]\n",
    ")\n",
    "blanding_av_vh_og_andre[\"bedr_salgsint\"] = round(\n",
    "    blanding_av_vh_og_andre[\"resten1\"] * blanding_av_vh_og_andre[\"nokkel\"]\n",
    ")\n",
    "blanding_av_vh_og_andre[\"bedr_forbruk\"] = round(\n",
    "    blanding_av_vh_og_andre[\"resten2\"] * blanding_av_vh_og_andre[\"nokkel\"]\n",
    ")\n",
    "\n",
    "# Combine the two subsets back into 'andre'\n",
    "andre = pd.concat([vh_bedriftene, blanding_av_vh_og_andre], ignore_index=True)\n",
    "\n",
    "andre.sort_values(by=[\"orgnr_n_1\", \"lopenr\"], inplace=True)\n",
    "\n",
    "oppdatere_hv = pd.concat([vhf_df, andre], ignore_index=True)\n",
    "\n",
    "oppdatere_hv = oppdatere_hv[\n",
    "    [\"orgnr_n_1\", \"lopenr\", \"radnr\", \"bedr_forbruk\", \"bedr_salgsint\"]\n",
    "]\n",
    "\n",
    "oppdatere_hv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enhetene_brukes2 = pd.merge(\n",
    "    enhetene_brukes, oppdatere_hv, on=[\"orgnr_n_1\", \"lopenr\", \"radnr\"]\n",
    ")\n",
    "\n",
    "enhetene_brukes2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Identify IDs that appear more than once\n",
    "duplicate_ids = enhetene_brukes2['id'][enhetene_brukes2['id'].duplicated(keep=False)]\n",
    "\n",
    "# Step 2: Update regtype to '02' where regtype is '01' and the id appears more than once\n",
    "enhetene_brukes2.loc[(enhetene_brukes2['regtype'] == '01') & (enhetene_brukes2['id'].isin(duplicate_ids)), 'regtype'] = '02'\n",
    "\n",
    "enhetene_brukes2.loc[enhetene_brukes2['regtype'] == '01', 'new_oms'] = enhetene_brukes2['foretak_omsetning']\n",
    "enhetene_brukes2.loc[enhetene_brukes2['regtype'] == '01', 'new_drkost'] = enhetene_brukes2['foretak_driftskostnad']\n",
    "enhetene_brukes2.loc[enhetene_brukes2['regtype'] == '01', 'bedr_salgsint'] = enhetene_brukes2['salgsint']\n",
    "enhetene_brukes2.loc[enhetene_brukes2['regtype'] == '01', 'bedr_forbruk'] = enhetene_brukes2['forbruk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enhetene_brukes2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### TEST\n",
    "test_grouped = (\n",
    "    enhetene_brukes2.groupby(\"id\")[[\"new_drkost\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "test_grouped.rename(\n",
    "    columns={\"new_drkost\": \"test_tot_drkost_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "test1 = pd.merge(enhetene_brukes2, test_grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "test1['drkost_diff'] = test1['foretak_driftskostnad'] - test1['test_tot_drkost_fordelt']\n",
    "\n",
    "test1 = test1.sort_values(by='drkost_diff', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_grouped = (\n",
    "    enhetene_brukes2.groupby(\"id\")[[\"new_oms\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "test_grouped.rename(\n",
    "    columns={\"new_oms\": \"test_tot_oms_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "test2 = pd.merge(enhetene_brukes2, test_grouped, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test2['oms_diff'] = test2['foretak_omsetning'] - test2['test_tot_oms_fordelt']\n",
    "\n",
    "test2 = test2.sort_values(by='oms_diff', ascending=True)\n",
    "\n",
    "# change pd option to show all rows \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rettes = enhetene_brukes2.copy()\n",
    "rettes[\"new_drkost\"].isna().sum()\n",
    "rettes[\"oms\"] = rettes[\"new_oms\"]\n",
    "rettes[\"driftsk\"] = rettes[\"gjeldende_driftsk_kr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert columns to numeric\n",
    "rettes[\"tot_driftskost_fordelt\"] = pd.to_numeric(\n",
    "    rettes[\"tot_driftskost_fordelt\"], errors=\"coerce\"\n",
    ")\n",
    "rettes[\"driftsk\"] = pd.to_numeric(rettes[\"driftsk\"], errors=\"coerce\")\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "# rettes[\"drkost_share\"] = rettes[\"driftsk\"] / rettes[\"tot_driftskost_fordelt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rettes[\"drkost_share\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rettes[\"new_drkost\"] = rettes[\"drkost_share\"] * rettes[\"foretak_driftskostnad\"]\n",
    "# rettes[\"new_drkost\"] = rettes[\"new_drkost\"].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# rettes[\"profit_ratio\"] = rettes[\"foretak_driftskostnad\"] / rettes[\"foretak_omsetning\"]\n",
    "\n",
    "# # if tot_driftskost_fordelt = 0 and 'new_drkost' is NaN then new_drkost = \"profit_ratio\" * new_oms\n",
    "# rettes[\"new_drkost\"] = np.where(\n",
    "#     (rettes[\"tot_driftskost_fordelt\"] == 0) & (rettes[\"new_drkost\"].isna()),\n",
    "#     rettes[\"profit_ratio\"] * rettes[\"new_oms\"],\n",
    "#     rettes[\"new_drkost\"],\n",
    "# )\n",
    "\n",
    "# rettes[\"new_drkost\"].isna().sum()\n",
    "\n",
    "# # set \"new_drkost\" nan to 0\n",
    "# rettes[\"new_drkost\"] = rettes[\"new_drkost\"].fillna(0)\n",
    "# rettes[\"new_drkost\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### TEST RETTES\n",
    "\n",
    "#### TEST\n",
    "test_grouped = (\n",
    "    rettes.groupby(\"id\")[[\"new_drkost\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "test_grouped.rename(\n",
    "    columns={\"new_drkost\": \"test_tot_drkost_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "test1 = pd.merge(rettes, test_grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "test1['drkost_diff'] = test1['foretak_driftskostnad'] - test1['test_tot_drkost_fordelt']\n",
    "\n",
    "test1 = test1.sort_values(by='drkost_diff', ascending=True)\n",
    "\n",
    "test_grouped = (\n",
    "    rettes.groupby(\"id\")[[\"new_oms\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "test_grouped.rename(\n",
    "    columns={\"new_oms\": \"test_tot_oms_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "test2 = pd.merge(rettes, test_grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "test2['oms_diff'] = test2['foretak_omsetning'] - test2['test_tot_oms_fordelt']\n",
    "\n",
    "test2 = test2.sort_values(by='oms_diff', ascending=True)\n",
    "\n",
    "# change pd option to show all rows \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Kontrol Drkost for forbuk og lÃ¸nn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rettes2 = rettes.copy()\n",
    "\n",
    "\n",
    "\n",
    "rettes2[\"drkost_temp\"] = rettes2[\"new_drkost\"]\n",
    "\n",
    "# Fill NaN in 'drkost_temp' with 0\n",
    "rettes2[\"drkost_temp\"] = rettes2[\"drkost_temp\"].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# replace comma with a '.' for gjeldende_lonn_kr\n",
    "rettes2[\"gjeldende_lonn_kr\"] = rettes2[\"gjeldende_lonn_kr\"].str.replace(\",\", \".\")\n",
    "\n",
    "rettes2[\"gjeldende_lonn_kr\"] = pd.to_numeric(\n",
    "    rettes2[\"gjeldende_lonn_kr\"], errors=\"coerce\"\n",
    ").fillna(0)\n",
    "\n",
    "# rettes2[\"bedr_forbruk\"] = rettes2[\"bedr_forbruk\"].str.replace(\",\", \".\")\n",
    "rettes2[\"bedr_forbruk\"] = pd.to_numeric(\n",
    "    rettes2[\"bedr_forbruk\"], errors=\"coerce\"\n",
    ").fillna(0)\n",
    "\n",
    "\n",
    "rettes2[\"lonn_+_forbruk\"] = rettes2[\"gjeldende_lonn_kr\"] + rettes2[\"bedr_forbruk\"]\n",
    "\n",
    "\n",
    "\n",
    "# Perform the if operation\n",
    "condition = rettes2[\"drkost_temp\"] < rettes2[\"lonn_+_forbruk\"]\n",
    "rettes2[\"drkost_temp\"] = np.where(\n",
    "    condition, rettes2[\"lonn_+_forbruk\"], rettes2[\"drkost_temp\"]\n",
    ")\n",
    "rettes2[\"theif\"] = np.where(condition, 1, 0)\n",
    "\n",
    "rettes2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame\n",
    "dkvars = rettes2[rettes2.groupby(\"orgnr_n_1\")[\"theif\"].transform(\"any\")]\n",
    "\n",
    "dkvars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate 'utskudd'\n",
    "dkvars[\"utskudd\"] = (\n",
    "    dkvars[\"new_drkost\"] - dkvars[\"gjeldende_lonn_kr\"] - dkvars[\"bedr_forbruk\"]\n",
    ")\n",
    "dkvars[\"utskudd\"] = abs(dkvars[\"utskudd\"])\n",
    "\n",
    "# Keep selected columns\n",
    "columns_to_keep = [\n",
    "    \"orgnr_n_1\",\n",
    "    \"lopenr\",\n",
    "    \"radnr\",\n",
    "    \"utskudd\",\n",
    "    \"new_drkost\",\n",
    "    \"drkost_temp\",\n",
    "    \"theif\",\n",
    "    \"gjeldende_lonn_kr\",\n",
    "    \"bedr_forbruk\",\n",
    "]\n",
    "dkvars = dkvars[columns_to_keep]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "dkvars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate sum of 'utskudd' grouped by 'orgnr_foretak', 'lopenr', and 'tyv'\n",
    "sum7b = dkvars.groupby([\"orgnr_n_1\", \"lopenr\", \"theif\"])[\"utskudd\"].sum().reset_index()\n",
    "\n",
    "# Display the result\n",
    "sum7b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transpose the result\n",
    "sum7b_transposed = sum7b.pivot(\n",
    "    index=[\"orgnr_n_1\", \"lopenr\"], columns=\"theif\", values=\"utskudd\"\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns as per SAS code\n",
    "sum7b_transposed.rename(columns={0: \"thief0\", 1: \"thief1\"}, inplace=True)\n",
    "\n",
    "sum7b_transposed = sum7b_transposed[[\"orgnr_n_1\", \"lopenr\", \"thief0\", \"thief1\"]]\n",
    "\n",
    "# Display the transposed result\n",
    "sum7b_transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge sums\n",
    "dkvars_2 = pd.merge(dkvars, sum7b_transposed, on=[\"orgnr_n_1\", \"lopenr\"], how=\"inner\")\n",
    "# dkvars_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply conditional logic\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "dkvars_2[\"andel1\"] = np.where(\n",
    "    dkvars_2[\"theif\"] == 0, dkvars_2[\"utskudd\"] / dkvars_2[\"thief0\"], np.nan\n",
    ")\n",
    "dkvars_2[\"andel2\"] = np.where(\n",
    "    dkvars_2[\"theif\"] == 0, np.round(dkvars_2[\"andel1\"] * dkvars_2[\"thief1\"]), np.nan\n",
    ")\n",
    "# dkvars_2['new_drkost'] = np.where(dkvars_2['theif'] == 0, np.sum(dkvars_2['drkost_temp'] - dkvars_2['andel2'], axis=0), dkvars_2['drkost_temp'])\n",
    "dkvars_2[\"new_drkost\"] = np.where(\n",
    "    dkvars_2[\"theif\"] == 0,\n",
    "    dkvars_2[\"drkost_temp\"] - dkvars_2[\"andel2\"],\n",
    "    dkvars_2[\"drkost_temp\"],\n",
    ")\n",
    "\n",
    "# Keep selected columns\n",
    "columns_to_keep = [\"orgnr_n_1\", \"lopenr\", \"radnr\", \"new_drkost\"]\n",
    "dkvars_3 = dkvars_2[columns_to_keep]\n",
    "\n",
    "# dkvars_2.head(50)\n",
    "\n",
    "good_final = dkvars_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dkvars_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(rettes2, dkvars_3, how='left', left_on=['orgnr_n_1', 'lopenr', 'radnr'], right_on=['orgnr_n_1', 'lopenr', 'radnr'], suffixes=('', '_updated'))\n",
    "\n",
    "# # Step 1: Identify IDs that appear more than once\n",
    "# duplicate_ids = merged_df['id'][merged_df['id'].duplicated(keep=False)]\n",
    "\n",
    "# # Step 2: Update regtype to '02' where regtype is '01' and the id appears more than once\n",
    "# merged_df.loc[(merged_df['regtype'] == '01') & (merged_df['id'].isin(duplicate_ids)), 'regtype'] = '02'\n",
    "\n",
    "# merged_df.loc[merged_df['regtype'] == '01', 'new_oms'] = merged_df['foretak_omsetning']\n",
    "# merged_df.loc[merged_df['regtype'] == '01', 'new_drkost'] = merged_df['foretak_driftskostnad']\n",
    "# merged_df.loc[merged_df['regtype'] == '01', 'bedr_salgsint'] = merged_df['salgsint']\n",
    "# merged_df.loc[merged_df['regtype'] == '01', 'bedr_forbruk'] = merged_df['forbruk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df['new_drkost'] = merged_df['new_drkost_updated'].combine_first(merged_df['new_drkost'])\n",
    "\n",
    "duplicate_ids = merged_df['id'][merged_df['id'].duplicated(keep=False)]\n",
    "\n",
    "# Step 2: Update regtype to '02' where regtype is '01' and the id appears more than once\n",
    "merged_df.loc[(merged_df['regtype'] == '01') & (merged_df['id'].isin(duplicate_ids)), 'regtype'] = '02'\n",
    "\n",
    "merged_df.loc[enhetene_brukes2['regtype'] == '01', 'new_oms'] = merged_df['foretak_omsetning']\n",
    "merged_df.loc[merged_df['regtype'] == '01', 'new_drkost'] = merged_df['foretak_driftskostnad']\n",
    "merged_df.loc[merged_df['regtype'] == '01', 'bedr_salgsint'] = merged_df['salgsint']\n",
    "merged_df.loc[merged_df['regtype'] == '01', 'bedr_forbruk'] = merged_df['forbruk']\n",
    "\n",
    "test_grouped = (\n",
    "    merged_df.groupby(\"id\")[[\"new_drkost\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "test_grouped.rename(\n",
    "    columns={\"new_drkost\": \"test_tot_drkost_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "temp = pd.merge(merged_df, test_grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "temp['drkost_diff'] = temp['foretak_driftskostnad'] - temp['test_tot_drkost_fordelt']\n",
    "\n",
    "temp = temp.sort_values(by='drkost_diff', ascending=True)\n",
    "\n",
    "mask = temp['drkost_diff'].abs() <= 1000\n",
    "\n",
    "# Create a new DataFrame with the rows to be excluded\n",
    "check_manually = merged_df[~mask]\n",
    "\n",
    "# Update the original DataFrame to keep only the rows where the absolute value of 'drkost_diff' is <= 1000\n",
    "merged_df = merged_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### TEST RETTES\n",
    "\n",
    "#### TEST\n",
    "test_grouped = (\n",
    "    merged_df.groupby(\"id\")[[\"new_drkost\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "test_grouped.rename(\n",
    "    columns={\"new_drkost\": \"test_tot_drkost_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "test1 = pd.merge(merged_df, test_grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "test1['drkost_diff'] = test1['foretak_driftskostnad'] - test1['test_tot_drkost_fordelt']\n",
    "\n",
    "test1 = test1.sort_values(by='drkost_diff', ascending=False)\n",
    "\n",
    "test_grouped = (\n",
    "    merged_df.groupby(\"id\")[[\"new_oms\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "test_grouped.rename(\n",
    "    columns={\"new_oms\": \"test_tot_oms_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "test2 = pd.merge(merged_df, test_grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "test2['oms_diff'] = test2['foretak_omsetning'] - test2['test_tot_oms_fordelt']\n",
    "\n",
    "test2 = test2.sort_values(by='oms_diff', ascending=True)\n",
    "\n",
    "# change pd option to show all rows \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Start of control for industry variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aar = 2021\n",
    "\n",
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{aar}/statistikkfil_bedrifter_nr.parquet\"\n",
    "    )\n",
    "    if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Use the ParquetDataset to read multiple files\n",
    "dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "table = dataset.read()\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "industri = table.to_pandas()\n",
    "\n",
    "\n",
    "\n",
    "industri = industri[['enhets_id','orgnr_bedrift','nopost_p4295','nopost_p4995','nopost_p6200', 'naring_f']]\n",
    "\n",
    "# filter for where substr first 2 characters of naring_f is in 45, 46 or 47\n",
    "industri = industri[industri['naring_f'].str[:2].isin(['45', '46', '47'])]\n",
    "\n",
    "# rename columns\n",
    "industri.rename(columns={'enhets_id': 'id', 'orgnr_bedrift': 'v_orgnr'}, inplace=True)\n",
    "\n",
    "industri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(merged_df.shape)\n",
    "print(industri.shape)\n",
    "\n",
    "# merge with left join on id and v_orgnr\n",
    "enhetene_brukes7b  = pd.merge(merged_df, industri, how='left', on=['id', 'v_orgnr'])\n",
    "print(enhetene_brukes7b.shape)\n",
    "\n",
    "# fill nan for bedr_forbruk, bedr_salgsint, nopost_p4295, nopost_p4995, nopost_p6200\n",
    "enhetene_brukes7b ['bedr_forbruk'] = enhetene_brukes7b ['bedr_forbruk'].fillna(0)\n",
    "enhetene_brukes7b ['bedr_salgsint'] = enhetene_brukes7b ['bedr_salgsint'].fillna(0)\n",
    "enhetene_brukes7b ['nopost_p4295'] = enhetene_brukes7b ['nopost_p4295'].fillna(0)\n",
    "enhetene_brukes7b ['nopost_p4995'] = enhetene_brukes7b ['nopost_p4995'].fillna(0)\n",
    "enhetene_brukes7b ['nopost_p6200'] = enhetene_brukes7b ['nopost_p6200'].fillna(0)\n",
    "\n",
    "#fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enhetene_brukes7c = enhetene_brukes7b.copy()\n",
    "enhetene_brukes7c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fill new_drkost_updated NaN with new_drkost\n",
    "# enhetene_brukes7c[\"new_drkost_updated\"] = enhetene_brukes7c[\n",
    "#     \"new_drkost_updated\"\n",
    "# ].fillna(enhetene_brukes7c[\"new_drkost\"])\n",
    "\n",
    "# rename\n",
    "enhetene_brukes7c.rename(\n",
    "    columns={\n",
    "        \"orgnr_n_1\": \"orgnr_foretak\",\n",
    "        \"new_drkost_updated\": \"tmp_ny_driftsk\",\n",
    "        \"tmp_sn2007_5\": \"naring\",\n",
    "        \"nacef_5\": \"foretaksnaring\",\n",
    "        \"nopost_p4295\": \"no4295\",\n",
    "        \"nopost_p4995\": \"no4995\",\n",
    "        \"nopost_p6200\": \"no6200\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "industrivars = enhetene_brukes7c[[\"id\",\"orgnr_foretak\", \"lopenr\", \"radnr\", \"tmp_ny_driftsk\", \"naring\", \"foretaksnaring\", \"no4295\", \"no4995\", \"no6200\", 'foretak_driftskostnad', 'gjeldende_lonn_kr', 'bedr_forbruk']]\n",
    "\n",
    "# sort by orgnr_foretak, lopenr, radnr\n",
    "industrivars = industrivars.sort_values(by=[\"orgnr_foretak\", \"lopenr\", \"radnr\"])\n",
    "\n",
    "industrivars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# industrivars['gjeldende_lonn_kr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n2 = substring first two charaters of naring\n",
    "# fill naring NaN with foretaksnaring\n",
    "industrivars[\"naring\"] = industrivars[\"naring\"].fillna(industrivars[\"foretaksnaring\"])\n",
    "industrivars[\"n2\"] = industrivars[\"naring\"].str[:2]\n",
    "\n",
    "# change n2 to int\"\n",
    "industrivars[\"n2\"] = industrivars[\"n2\"].astype(int)\n",
    "\n",
    "# create new variable called _industribedrift which shall = 1 if n2 greater than or equal to 05 or less than or equal to 33\n",
    "industrivars[\"_industribedrift\"] = np.where(\n",
    "    (industrivars[\"n2\"] >= 5) & (industrivars[\"n2\"] <= 33), 1, 0\n",
    ")\n",
    "\n",
    "# Filter the DataFrame where _industribedrift is 1\n",
    "filtered_df = industrivars[industrivars['_industribedrift'] == 1]\n",
    "\n",
    "# Select distinct rows based on orgnr_foretak, lopenr, and _industribedrift\n",
    "distinct_df = filtered_df[['orgnr_foretak', 'lopenr', '_industribedrift']].drop_duplicates()\n",
    "\n",
    "# Rename the _industribedrift column to _har_indr\n",
    "distinct_df = distinct_df.rename(columns={'_industribedrift': '_har_indr'})\n",
    "\n",
    "# Sort the DataFrame by orgnr_foretak and lopenr\n",
    "indrbed = distinct_df.sort_values(by=['orgnr_foretak', 'lopenr'])\n",
    "\n",
    "del filtered_df, distinct_df\n",
    "\n",
    "indrbed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "industrivars = pd.merge(industrivars, indrbed, on=['orgnr_foretak', 'lopenr'], how='left', indicator=True)\n",
    "\n",
    "# Filter the rows to include only those present in 'industrivars' or in both 'industrivars' and 'indrbed'\n",
    "industrivars = industrivars[(industrivars['_merge'] == 'both') | (industrivars['_merge'] == 'left_only')]\n",
    "\n",
    "# Drop the '_merge' column\n",
    "industrivars = industrivars.drop(columns=['_merge'])\n",
    "\n",
    "# sort by orgnr_foretak, lopenr, radnr\n",
    "industrivars = industrivars.sort_values(by=[\"orgnr_foretak\", \"lopenr\", \"radnr\"])\n",
    "\n",
    "industrivars = industrivars.fillna(0)\n",
    "\n",
    "\n",
    "industrivars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summing for industribedriftebne\n",
    "sum101 = industrivars[industrivars['_industribedrift'] == 1].groupby(['orgnr_foretak', 'lopenr'])['tmp_ny_driftsk'].sum().reset_index()\n",
    "sum101 = sum101.rename(columns={'tmp_ny_driftsk': 'fdk_indr'})\n",
    "\n",
    "# Summing for vanlige bedrifter\n",
    "sum102 = industrivars[industrivars['_industribedrift'] == 0].groupby(['orgnr_foretak', 'lopenr'])['tmp_ny_driftsk'].sum().reset_index()\n",
    "sum102 = sum102.rename(columns={'tmp_ny_driftsk': 'fdk_vanl'})\n",
    "\n",
    "# Joining sum101 with industrivars\n",
    "industrivars = pd.merge(industrivars, sum101, on=['orgnr_foretak', 'lopenr'], how='left')\n",
    "\n",
    "# Joining sum102 with industrivars\n",
    "industrivars = pd.merge(industrivars, sum102, on=['orgnr_foretak', 'lopenr'], how='left')\n",
    "\n",
    "# Sorting the final DataFrame\n",
    "industrivars = industrivars.sort_values(by=['orgnr_foretak', 'lopenr', 'radnr'])\n",
    "\n",
    "# fill Nan for _har_indr, fdk_indr, fdk_vanl with 0\n",
    "industrivars = industrivars.fillna(0)\n",
    "\n",
    "industrivars.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aar = 2021\n",
    "\n",
    "fil_path = [\n",
    "    f\n",
    "    for f in fs.glob(\n",
    "        f\"gs://ssb-prod-noeku-data-produkt/statistikkfiler/g{aar}/statistikkfil_foretak_nr.parquet\"\n",
    "    )\n",
    "    if f.endswith(\".parquet\")\n",
    "]\n",
    "\n",
    "# Use the ParquetDataset to read multiple files\n",
    "dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "table = dataset.read()\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "foretak = table.to_pandas()\n",
    "\n",
    "\n",
    "\n",
    "foretak = foretak[[\"enhets_id\",'orgnr_foretak','nopost_p4005','nopost_p4295','nopost_p4995','nopost_p6200', 'naring_f', 'reg_type']]\n",
    "\n",
    "# filter for where substr first 2 characters of naring_f is in 45, 46 or 47\n",
    "foretak = foretak[foretak['naring_f'].str[:2].isin(['45', '46', '47'])]\n",
    "\n",
    "# rename columns\n",
    "foretak.rename(\n",
    "    columns={\n",
    "        \"naring_f\": \"foretaksnaring\",\n",
    "        \"enhets_id\": \"id\",\n",
    "        \"nopost_p4295\": \"no4295_f\",\n",
    "        \"nopost_p4995\": \"no4995_f\",\n",
    "        \"nopost_p6200\": \"no6200_f\",\n",
    "        \"nopost_p4005\": \"forbruk_f\"\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "foretak = foretak[[\"id\", \"no4295_f\", \"no4995_f\", \"no6200_f\"]]\n",
    "\n",
    "# drop duplicate orgnr_foretak and reset index\n",
    "foretak = foretak.drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "foretak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the data types of orgnr_foretak in both DataFrames\n",
    "# print(foretak['orgnr_foretak'].dtype)\n",
    "# print(industrivars['orgnr_foretak'].dtype)\n",
    "\n",
    "# # Ensure they are the same type, if not, convert them to string\n",
    "# foretak['orgnr_foretak'] = foretak['orgnr_foretak'].astype(str)\n",
    "# industrivars['orgnr_foretak'] = industrivars['orgnr_foretak'].astype(str)\n",
    "\n",
    "# # Remove leading/trailing spaces\n",
    "# foretak['orgnr_foretak'] = foretak['orgnr_foretak'].str.strip()\n",
    "# industrivars['orgnr_foretak'] = industrivars['orgnr_foretak'].str.strip()\n",
    "\n",
    "\n",
    "# Check for common values\n",
    "common_values = set(foretak['id']).intersection(set(industrivars['id']))\n",
    "print(f\"Number of common orgnr_foretak: {len(common_values)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "foretak_filtered = foretak[foretak['id'].isin(industrivars['id'])]\n",
    "foretak_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perform left merge on 'id'\n",
    "industrivars = pd.merge(industrivars,\n",
    "    foretak_filtered, on=['id'], how='left'\n",
    ")\n",
    "\n",
    "industrivars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the function to calculate 'andelen'\n",
    "def calculate_andelen(row):\n",
    "    if row['_har_indr'] == 0:\n",
    "        return row['tmp_ny_driftsk'] / row['foretak_driftskostnad'] if row['foretak_driftskostnad'] != 0 else 0\n",
    "    elif row['_har_indr'] == 1 and row['_industribedrift'] == 0:\n",
    "        return 0\n",
    "    elif row['_har_indr'] == 1 and row['_industribedrift'] == 1:\n",
    "        return row['tmp_ny_driftsk'] / row['fdk_indr'] if row['fdk_indr'] != 0 else 0\n",
    "    return 0\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "industrivars['andelen'] = industrivars.apply(calculate_andelen, axis=1)\n",
    "\n",
    "industrivars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Create the 'dk' column\n",
    "industrivars['dk'] = industrivars['tmp_ny_driftsk']\n",
    "\n",
    "# Step 2: Create the 'x' column by summing the specified columns\n",
    "industrivars['x'] = industrivars[['gjeldende_lonn_kr', 'bedr_forbruk', 'no4295', 'no4995', 'no6200']].sum(axis=1)\n",
    "\n",
    "# Step 3: Initialize the 'dknye' column with the value of 'dk'\n",
    "industrivars['dknye'] = industrivars['dk']\n",
    "\n",
    "# Step 4: Create the 'tyv' column and set it to 0 by default\n",
    "industrivars['tyv'] = 0\n",
    "\n",
    "# Step 5: Apply the condition to update 'dknye' and 'tyv'\n",
    "condition = (industrivars['x'] > industrivars['dk'])\n",
    "industrivars.loc[condition, 'dknye'] = industrivars['x']\n",
    "industrivars.loc[condition, 'tyv'] = 1\n",
    "\n",
    "# sort the DataFrame\n",
    "industrivars = industrivars.sort_values(by=['id', 'lopenr', 'radnr']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "industrivars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df = industrivars[(industrivars['tyv'] == 1)]\n",
    "\n",
    "tyvers = filtered_df[['id', 'lopenr']]\n",
    "# drop duplicates for id\n",
    "tyvers = tyvers.drop_duplicates(subset=['id'])\n",
    "\n",
    "tyvers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "industrivars = industrivars[industrivars['id'].isin(tyvers['id'])]\n",
    "\n",
    "industrivars = industrivars.sort_values(by=['orgnr_foretak', 'lopenr', 'tyv']).reset_index(drop=True)\n",
    "\n",
    "industrivars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the 'utskudd' column\n",
    "industrivars['utskudd'] = industrivars[['dk', 'gjeldende_lonn_kr', 'bedr_forbruk', 'no4295_f', 'no4995_f', 'no6200_f']].apply(lambda x: x[0] - x[1:].sum(), axis=1)\n",
    "industrivars['utskudd'] = industrivars['utskudd'].abs()\n",
    "\n",
    "# Replace missing values in 'tyv' with 0\n",
    "industrivars['tyv'] = industrivars['tyv'].fillna(0)\n",
    "\n",
    "# Keep only the specified columns\n",
    "industrivars = industrivars[['orgnr_foretak', 'lopenr', 'radnr', 'utskudd', 'dk', 'dknye', 'tyv']]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "industrivars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum7bb = industrivars.groupby(['orgnr_foretak', 'lopenr', 'tyv'], as_index=False)['utskudd'].sum()\n",
    "\n",
    "\n",
    "# Pivot the table to create a wide format\n",
    "sum7bb_pivot = sum7bb.pivot(index=['orgnr_foretak', 'lopenr'], columns='tyv', values='utskudd').reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "sum7bb_pivot = sum7bb_pivot.rename(columns={0: 'tyv0', 1: 'tyv1'})\n",
    "\n",
    "# Merge the pivoted sums back into the original industrivars DataFrame\n",
    "merged_df = pd.merge(industrivars, sum7bb_pivot, on=['orgnr_foretak', 'lopenr'], how='inner')\n",
    "\n",
    "# Initialize andel1, andel2 with NaN\n",
    "merged_df['andel1'] = np.nan\n",
    "merged_df['andel2'] = np.nan\n",
    "\n",
    "# Update andel1 where tyv == 0\n",
    "merged_df.loc[merged_df['tyv'] == 0, 'andel1'] = merged_df['utskudd'] / merged_df['tyv0']\n",
    "\n",
    "# Update andel2 where tyv == 0\n",
    "merged_df.loc[merged_df['tyv'] == 0, 'andel2'] = np.round(merged_df['andel1'] * merged_df['tyv1'])\n",
    "\n",
    "# Update tmp_ny_driftsk based on conditions\n",
    "merged_df.loc[merged_df['tyv'] == 0, 'tmp_ny_driftsk'] = merged_df['dknye'] - merged_df['andel2']\n",
    "merged_df.loc[merged_df['tyv'] == 1, 'tmp_ny_driftsk'] = merged_df['dknye']\n",
    "\n",
    "# \n",
    "\n",
    "# Keep only the specified columns\n",
    "filtered_merged_df = merged_df[['orgnr_foretak', 'lopenr', 'radnr', 'tmp_ny_driftsk']]\n",
    "\n",
    "\n",
    "filtered_merged_df.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(enhetene_brukes7c, filtered_merged_df, on=['orgnr_foretak', 'lopenr', 'radnr'], how='left', indicator=True)\n",
    "\n",
    "print(merged_df.shape)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the 'new_drkost' column based on the value of '_merge'\n",
    "\n",
    "# fill tmp_ny_driftsk_y NaN with 0\n",
    "merged_df['tmp_ny_driftsk_y'] = merged_df['tmp_ny_driftsk_y'].fillna(0)\n",
    "\n",
    "merged_df['tmp_ny_driftsk'] = np.where(merged_df['_merge'] == 'left_only', \n",
    "                                   merged_df['tmp_ny_driftsk_x'], \n",
    "                                   np.where(merged_df['_merge'] == 'both', \n",
    "                                            merged_df['tmp_ny_driftsk_y'], \n",
    "                                            np.nan))\n",
    "\n",
    "\n",
    "merged_df.loc[merged_df['regtype'] == '01', 'new_oms'] = merged_df['foretak_omsetning']\n",
    "merged_df.loc[merged_df['regtype'] == '01', 'new_drkost'] = merged_df['foretak_driftskostnad']\n",
    "merged_df.loc[merged_df['regtype'] == '01', 'tmp_ny_driftsk'] = merged_df['foretak_driftskostnad']\n",
    "merged_df.loc[merged_df['regtype'] == '01', 'bedr_salgsint'] = merged_df['salgsint']\n",
    "merged_df.loc[merged_df['regtype'] == '01', 'bedr_forbruk'] = merged_df['forbruk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "grouped = (\n",
    "    merged_df.groupby(\"id\")[[\"tmp_ny_driftsk\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "grouped.rename(\n",
    "    columns={\"tmp_ny_driftsk\": \"tot_drkost_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "final_adjustment = pd.merge(merged_df, grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "final_adjustment['diff'] = final_adjustment['foretak_driftskostnad'] - final_adjustment['tot_drkost_fordelt']\n",
    "\n",
    "# sort difference in descending order\n",
    "final_adjustment = final_adjustment.sort_values(by=\"diff\", ascending=True)\n",
    "\n",
    "final_adjustment.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# count NaN values for new_drkost\n",
    "merged_df['tmp_ny_driftsk'].isna().sum()\n",
    "\n",
    "# # create new df where new_drkost is NaN\n",
    "test = merged_df[merged_df['tmp_ny_driftsk'].isna()]\n",
    "\n",
    "# 'new_drkost' = merged_df['tmp_ny_driftsk']\n",
    "\n",
    "merged_df['new_drkost'] = merged_df['tmp_ny_driftsk']\n",
    "\n",
    "merged_df[\"tmp_sn2007_5\"] = merged_df[\"naring\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fill bedr_forbruk Nan with 0\n",
    "merged_df['bedr_forbruk'] = merged_df['bedr_forbruk'].fillna(0)\n",
    "merged_df['bedr_salgsint'] = merged_df['bedr_salgsint'].fillna(0)\n",
    "merged_df['oms'] = merged_df['oms'].fillna(0)\n",
    "merged_df['new_drkost'] = merged_df['new_drkost'].fillna(0)\n",
    "\n",
    "merged_df[\"n3\"] = merged_df[\"tmp_sn2007_5\"].str[:4]\n",
    "# merged_df[\"lonn\"] = merged_df[\"lonn\"].str.replace(',', '').astype(float)\n",
    "merged_df[\"lonn_pst_aordn\"] = merged_df[\"lonn_pst_aordn\"].str.replace(',', '').astype(float)\n",
    "\n",
    "# convert b_sysselsetting_syss  to int\n",
    "merged_df[\"b_sysselsetting_syss\"] = merged_df[\"b_sysselsetting_syss\"].astype(int)\n",
    "merged_df[\"fjor_driftskost_kr_t1\"] = merged_df[\"fjor_driftskost_kr_t1\"].astype(int)\n",
    "merged_df[\"fjor_lonn_kr_t1\"] = merged_df[\"fjor_lonn_kr_t1\"].astype(int)\n",
    "merged_df[\"fjor_omsetn_kr_t1\"] = merged_df[\"fjor_omsetn_kr_t1\"].astype(int)\n",
    "merged_df[\"fjor_snittlonn_t1\"] = merged_df[\"fjor_snittlonn_t1\"].astype(int)\n",
    "merged_df[\"fjor_snittoms_t1\"] = merged_df[\"fjor_snittoms_t1\"].astype(int)\n",
    "merged_df[\"fjor_syssel_t1\"] = merged_df[\"fjor_syssel_t1\"].astype(int)\n",
    "merged_df[\"tmp_forbruk_bed\"] = merged_df[\"tmp_forbruk_bed\"].astype(int)\n",
    "merged_df[\"tmp_ny_bdr_syss\"] = merged_df[\"tmp_ny_bdr_syss\"].astype(int)\n",
    "merged_df[\"tmp_salgsint_bed\"] = merged_df[\"tmp_salgsint_bed\"].astype(int)\n",
    "merged_df[\"tmp_snittlonn\"] = merged_df[\"tmp_snittlonn\"].astype(int)\n",
    "merged_df[\"tmp_snittoms\"] = merged_df[\"tmp_snittoms\"].astype(int)\n",
    "\n",
    "merged_df[\"fjor_nace_b_t1\"] = merged_df[\"fjor_nace_b_t1\"].astype(str)\n",
    "merged_df[\"regtype\"] = merged_df[\"regtype\"].astype(str)\n",
    "merged_df[\"tmp_sn2007_5\"] = merged_df[\"tmp_sn2007_5\"].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(merged_df.shape)\n",
    "# drop duplicates\n",
    "# merged_df = merged_df.drop_duplicates()\n",
    "# print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"n3\"] = merged_df[\"tmp_sn2007_5\"].str[:4]\n",
    "merged_df[\"n2\"] = merged_df[\"tmp_sn2007_5\"].str[:2]\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_parquet(\n",
    "    f\"gs://ssb-prod-noeku-data-produkt/temp/knn_varehandel_cleaned.parquet\",\n",
    "    storage_options={\"token\": AuthClient.fetch_google_credentials()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_knn.to_parquet(\n",
    "    f\"gs://ssb-prod-noeku-data-produkt/temp/timeseries_knn.parquet\",\n",
    "    storage_options={\"token\": AuthClient.fetch_google_credentials()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print option to show all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# print out all columns list in time_series_df \n",
    "# print(time_series_df.columns)\n",
    "# print(merged_df.columns)\n",
    "\n",
    "time_series_df[\"n3\"] = time_series_df[\"tmp_sn2007_5\"].str[:4]\n",
    "time_series_df[\"n2\"] = time_series_df[\"tmp_sn2007_5\"].str[:2]\n",
    "merged_df[\"n2\"] = merged_df[\"tmp_sn2007_5\"].str[:2]\n",
    "\n",
    "temp_1 = time_series_df[['id',\n",
    "                         'nacef_5',\n",
    "                         'orgnr_n_1',\n",
    "                         'b_sysselsetting_syss',\n",
    "                         'b_kommunenr',\n",
    "                         'gjeldende_lonn_kr', \n",
    "                         'gjeldende_driftsk_kr',\n",
    "                         'gjeldende_omsetn_kr',\n",
    "                         'tmp_forbruk_bed',\n",
    "                         'tmp_salgsint_bed',\n",
    "                         'tmp_sn2007_5',\n",
    "                         'n3',\n",
    "                         'n2',\n",
    "                         'year']]\n",
    "\n",
    "# rename columns\n",
    "temp_1 = temp_1.rename(columns={'b_sysselsetting_syss':'syss',\n",
    "                                'b_kommunenr':'kommunenr',\n",
    "                                'gjeldende_lonn_kr':'lonn',\n",
    "                                'gjeldende_omsetn_kr':'oms',\n",
    "                                'gjeldende_driftsk_kr': 'drkost',\n",
    "                                'tmp_forbruk_bed':'forbruk',\n",
    "                                'tmp_salgsint_bed':'salgsint',\n",
    "                               })\n",
    "\n",
    "temp_1 = temp_1[temp_1['year'] != 2021]\n",
    "\n",
    "temp_2 = merged_df[['id',\n",
    "                 'nacef_5',\n",
    "                 'orgnr_n_1',\n",
    "                 'b_sysselsetting_syss',\n",
    "                 'b_kommunenr',\n",
    "                 'gjeldende_lonn_kr', \n",
    "                 'new_drkost',\n",
    "                 'oms',\n",
    "                 'bedr_forbruk',\n",
    "                 'bedr_salgsint',\n",
    "                 'tmp_sn2007_5',\n",
    "                 'n3',\n",
    "                 'n2',\n",
    "                 'year']]\n",
    "\n",
    "temp_2 = temp_2.rename(columns={'b_sysselsetting_syss':'syss',\n",
    "                                'b_kommunenr':'kommunenr',\n",
    "                                'gjeldende_lonn_kr':'lonn',\n",
    "                                'bedr_forbruk':'forbruk',\n",
    "                                'bedr_salgsint':'salgsint',\n",
    "                                'new_drkost': 'drkost'\n",
    "                               })\n",
    "\n",
    "temp_2 = temp_2[temp_2['year'] == 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN for forbruk and salgint for temp_1\n",
    "temp_1['forbruk'] = temp_1['forbruk'].fillna(0)\n",
    "temp_1['salgsint'] = temp_1['salgsint'].fillna(0)\n",
    "temp_2['forbruk'] = temp_2['forbruk'].fillna(0)\n",
    "temp_2['salgsint'] = temp_2['salgsint'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_knn = pd.concat([temp_1, temp_2], axis=0)\n",
    "\n",
    "# timeseries_knn['resultat'] = timeseries_knn['oms'] - timeseries_knn['drkost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_knn.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate forbruk per year\n",
    "\n",
    "columns_to_convert = ['salgsint', 'forbruk', 'oms', 'drkost', 'lonn', 'syss']\n",
    "\n",
    "# Convert columns to integers using pd.to_numeric for safe conversion, errors='coerce' will set issues to NaN\n",
    "for column in columns_to_convert:\n",
    "    timeseries_knn[column] = pd.to_numeric(timeseries_knn[column], errors='coerce')\n",
    "\n",
    "timeseries_knn['year'] = timeseries_knn['year'].astype(str)\n",
    "timeseries_knn['n3'] = timeseries_knn['n3'].astype(str)\n",
    "\n",
    "timeseries_knn['resultat'] = timeseries_knn['oms'] - timeseries_knn['drkost']\n",
    "\n",
    "\n",
    "\n",
    "# filter for n3 in 45, 46 or 47\n",
    "timeseries_knn = timeseries_knn[timeseries_knn['n2'].isin(['45', '46', '47'])]\n",
    "temp = timeseries_knn.copy()\n",
    "timeseries_knn_agg = timeseries_knn.groupby([\"year\", \"n3\"])[[\"forbruk\", \"oms\", \"drkost\", \"salgsint\", \"lonn\", 'syss', \"resultat\"]].sum().reset_index()\n",
    "# timeseries_knn_agg = timeseries_knn.groupby([\"year\", \"n3\"])[[\"forbruk\", \"oms\", \"drkost\", \"salgsint\", \"lonn\", 'syss', \"resultat\"]].sum().reset_index()\n",
    "timeseries_knn_agg['lonn_pr_syss'] = timeseries_knn_agg['lonn'] / timeseries_knn_agg['syss']\n",
    "timeseries_knn_agg['oms_pr_syss'] = timeseries_knn_agg['oms'] / timeseries_knn_agg['syss']\n",
    "timeseries_knn_agg[\"n2\"] = timeseries_knn_agg[\"n3\"].str[:2]\n",
    "\n",
    "\n",
    "\n",
    "timeseries_knn__kommune_agg = temp.groupby([\"year\", \"kommunenr\", \"n3\"])[[\"forbruk\", \"oms\", \"drkost\", \"salgsint\", \"lonn\", 'syss', \"resultat\"]].sum().reset_index()\n",
    "timeseries_knn__kommune_agg['lonn_pr_syss'] = timeseries_knn__kommune_agg['lonn'] / timeseries_knn_agg['syss']\n",
    "timeseries_knn__kommune_agg['oms_pr_syss'] = timeseries_knn__kommune_agg['oms'] / timeseries_knn_agg['syss']\n",
    "timeseries_knn__kommune_agg[\"n2\"] = timeseries_knn__kommune_agg[\"n3\"].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeseries_knn__kommune_agg.head(50)\n",
    "\n",
    "# filter for when year = 2021\n",
    "\n",
    "test = timeseries_knn_agg[timeseries_knn_agg['year'] == '2021']\n",
    "timeseries_knn__kommune_agg.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fil_path = [\n",
    "#     f\n",
    "#     for f in fs.glob(\n",
    "#         f\"gs://ssb-prod-noeku-data-produkt/temp/timeseries_knn.parquet\"\n",
    "#     )\n",
    "#     if f.endswith(\".parquet\")\n",
    "# ]\n",
    "\n",
    "# # Use the ParquetDataset to read multiple files\n",
    "# dataset = pq.ParquetDataset(fil_path, filesystem=fs)\n",
    "# table = dataset.read()\n",
    "\n",
    "# # Convert to Pandas DataFrame\n",
    "# timeseries_knn_agg = table.to_pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_knn__kommune_agg.to_parquet(\n",
    "    f\"gs://ssb-prod-noeku-data-produkt/temp/timeseries_knn_kommune.parquet\",\n",
    "    storage_options={\"token\": AuthClient.fetch_google_credentials()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_knn_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('id').agg({\n",
    "    'oms': 'sum',\n",
    "    'new_drkost': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "# Merging the sums back with the original to compare\n",
    "comparison_df = pd.merge(merged_df, grouped_df, on='id', suffixes=('', '_sum'))\n",
    "\n",
    "\n",
    "# Check if the summed 'new_oms' and 'new_drkost' match 'foretak_omsetning' and 'foretak_driftskostnad'\n",
    "comparison_df['oms_match'] = comparison_df['foretak_omsetning'] == comparison_df['oms_sum']\n",
    "comparison_df['drkost_match'] = comparison_df['foretak_driftskostnad'] == comparison_df['new_drkost_sum']\n",
    "\n",
    "\n",
    "# Print rows where totals do not match\n",
    "# print(comparison_df[~(comparison_df['oms_match'] & comparison_df['drkost_match'])])\n",
    "\n",
    "check = comparison_df[~(comparison_df['oms_match'] & comparison_df['drkost_match'])]\n",
    "\n",
    "# Optionally, print out all rows to manually inspect\n",
    "# print(comparison_df)\n",
    "check['oms_diff'] = check['foretak_omsetning'] - check['oms_sum']\n",
    "check['drkost_diff'] = check['foretak_driftskostnad'] - check['new_drkost_sum']\n",
    "\n",
    "# filter for when either oms_diff or drkost_diff is not 0\n",
    "check[(check['oms_diff'] != 0) | (check['drkost_diff'] != 0)]\n",
    "\n",
    "# sort oms_diff\n",
    "check.sort_values(by=\"oms_diff\", ascending=True, inplace=True)\n",
    "\n",
    "check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST RETTES\n",
    "\n",
    "#### TEST\n",
    "test_grouped = (\n",
    "    merged_df.groupby(\"id\")[[\"new_drkost\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "test_grouped.rename(\n",
    "    columns={\"new_drkost\": \"test_tot_drkost_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "test1 = pd.merge(merged_df, test_grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "test1['drkost_diff'] = test1['foretak_driftskostnad'] - test1['test_tot_drkost_fordelt']\n",
    "\n",
    "test1 = test1.sort_values(by='drkost_diff', ascending=True)\n",
    "\n",
    "test_grouped = (\n",
    "    merged_df.groupby(\"id\")[[\"new_oms\"]].sum().reset_index()\n",
    ")\n",
    "\n",
    "test_grouped.rename(\n",
    "    columns={\"new_oms\": \"test_tot_oms_fordelt\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "test2 = pd.merge(merged_df, test_grouped, on=\"id\", how=\"left\")\n",
    "\n",
    "test2['oms_diff'] = test2['foretak_omsetning'] - test2['test_tot_oms_fordelt']\n",
    "\n",
    "test2 = test2.sort_values(by='oms_diff', ascending=True)\n",
    "\n",
    "# change pd option to show all rows \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test2.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
